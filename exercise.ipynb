{"cells":[{"block_group":"c5a5d10f6a724a4395c8594bcf9b38d5","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"24de8f956f8045838736dbf3061f5280","deepnote_block_group":"c5a5d10f6a724a4395c8594bcf9b38d5","deepnote_cell_type":"text-cell-h1","deepnote_sorting_key":"0","deepnote_source":"Kobold reverse engineering"},"source":"# Kobold reverse engineering"},{"block_group":"d41596c8ac0343f78d87af38d2684a65","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[{"url":"https://spectrum.ieee.org/ai-mining","type":"link","ranges":[],"toCodePoint":35,"fromCodePoint":12}],"cell_id":"a76761d79a0244219fc8a9c635028045","deepnote_block_group":"d41596c8ac0343f78d87af38d2684a65","deepnote_cell_type":"text-cell-p","deepnote_sorting_key":"1","deepnote_source":"Inspired by Golman and House (2023)."},"source":"Inspired by Golman and House \\(2023\\)\\."},{"block_group":"a94b1bc4a6f045e98431b87d180dc75f","cell_type":"markdown","execution_count":null,"metadata":{"deepnote_img_src":"architecture-20260205-023459.png","cell_id":"54c5185b4d6b42888a38ee789694b8d6","deepnote_block_group":"a94b1bc4a6f045e98431b87d180dc75f","deepnote_cell_type":"image","deepnote_sorting_key":"2","deepnote_source":""},"source":"<img src=\"architecture-20260205-023459.png\" width=\"\" align=\"\" />"},{"block_group":"c22c3e18ccd949aca2b9abc459359172","cell_type":"code","execution_count":12,"metadata":{"execution_start":1770257021116,"execution_millis":0,"source_hash":"a878f3e0","execution_context_id":"a3ebaa0d-42ee-47b9-ad2b-cdae02ced48a","cell_id":"c22c3e18ccd949aca2b9abc459359172","deepnote_block_group":"c22c3e18ccd949aca2b9abc459359172","deepnote_cell_type":"code","deepnote_sorting_key":"3","deepnote_content_hash":"a878f3e0","deepnote_execution_started_at":"2026-02-05T02:03:41.116Z","deepnote_execution_finished_at":"2026-02-05T02:03:41.116Z","deepnote_source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom scipy.interpolate import griddata\n\nimport gempy as gp\nfrom gempy.core.data import StructuralFrame\n\nimport lets_plot as lp\nlp.LetsPlot.setup_html()\n\ndevice = torch.device('cpu')\ntorch.manual_seed(42)"},"outputs":[{"data":{"text/html":"\n        <div id=\"EFxCyb\"></div>\n        <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n            if(!window.letsPlotCallQueue) {\n                window.letsPlotCallQueue = [];\n            };\n            window.letsPlotCall = function(f) {\n                window.letsPlotCallQueue.push(f);\n            };\n            (function() {\n                var script = document.createElement(\"script\");\n                script.type = \"text/javascript\";\n                script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.8.2/js-package/distr/lets-plot.min.js\";\n                script.onload = function() {\n                    window.letsPlotCall = function(f) {f();};\n                    window.letsPlotCallQueue.forEach(function(f) {f();});\n                    window.letsPlotCallQueue = [];\n                    \n                };\n                script.onerror = function(event) {\n                    window.letsPlotCall = function(f) {};    // noop\n                    window.letsPlotCallQueue = [];\n                    var div = document.createElement(\"div\");\n                    div.style.color = 'darkred';\n                    div.textContent = 'Error loading Lets-Plot JS';\n                    document.getElementById(\"EFxCyb\").appendChild(div);\n                };\n                var e = document.getElementById(\"EFxCyb\");\n                e.appendChild(script);\n            })()\n        </script>\n        "},"metadata":{},"output_type":"display_data"},{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"<torch._C.Generator at 0x7fb9f4239cd0>"},"metadata":{}}],"source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom scipy.interpolate import griddata\n\nimport gempy as gp\nfrom gempy.core.data import StructuralFrame\n\nimport lets_plot as lp\nlp.LetsPlot.setup_html()\n\ndevice = torch.device('cpu')\ntorch.manual_seed(42)"},{"block_group":"4ad78ae6358b44fcbeb33029494bc9ea","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"7a82cb9de6e04cafa656176d10bb7a02","deepnote_block_group":"4ad78ae6358b44fcbeb33029494bc9ea","deepnote_cell_type":"text-cell-h2","deepnote_sorting_key":"4","deepnote_source":"Create the sand box data set"},"source":"## Create the sand box data set"},{"block_group":"c9bff6afd3e049d8a2888b792f532e3c","cell_type":"code","execution_count":15,"metadata":{"execution_start":1770257024884,"execution_millis":4,"source_hash":"c8667353","execution_context_id":"a3ebaa0d-42ee-47b9-ad2b-cdae02ced48a","cell_id":"424a31f4058f4b169d4014d6884f365e","deepnote_block_group":"c9bff6afd3e049d8a2888b792f532e3c","deepnote_cell_type":"code","deepnote_sorting_key":"5","deepnote_content_hash":"c8667353","deepnote_execution_started_at":"2026-02-05T02:03:44.884Z","deepnote_execution_finished_at":"2026-02-05T02:03:44.888Z","deepnote_source":"from simpeg import maps\nfrom simpeg.potential_fields import magnetics, gravity\nfrom discretize import TensorMesh\n\n# 3D mesh: 4km × 4km × 1km deep\nnx, ny, nz = 16, 16, 8\ndx, dy, dz = 250, 250, 125\nmesh = TensorMesh(\n    [np.ones(nx)*dx, np.ones(ny)*dy, np.ones(nz)*dz],\n    origin=[0, 0, -nz*dz]\n)\nn_cells = mesh.nC\ncc = mesh.cell_centers\n\nprint(f\"Domain: {nx*dx}m × {ny*dy}m × {nz*dz}m\")\nprint(f\"Cells: {n_cells}\")\n\n# Two mineralized bodies: Cu-Ni sulfide lenses\nd1 = np.sqrt(((cc[:,0]-1500)/400)**2 + ((cc[:,1]-1500)/350)**2 + ((cc[:,2]+500)/150)**2)\nbody1 = np.exp(-d1**2 * 2)\n\nd2 = np.sqrt(((cc[:,0]-2800)/350)**2 + ((cc[:,1]-2500)/300)**2 + ((cc[:,2]+700)/120)**2)\nbody2 = np.exp(-d2**2 * 2)\n\n# Magnetic susceptibility (SI) — sulfides are moderately magnetic\nsusceptibility_true = 0.001 + body1 * 0.05 + body2 * 0.02\n\n# Density contrast (g/cc) — massive sulfides are denser than host rock\ndensity_true = 0.0 + body1 * 0.5 + body2 * 0.3\n\n# Mineral compositions (mass fractions)\nCu = 0.005 + body1 * 0.02 + body2 * 0.01\nNi = 0.003 + body1 * 0.01 + body2 * 0.025\nCo = 0.001 + body1 * 0.005 + body2 * 0.012\ngangue = 1 - Cu - Ni - Co\ncompositions = np.stack([Cu, Ni, Co, gangue], axis=1)\n\nprint(f\"χ:  {susceptibility_true.min():.4f} – {susceptibility_true.max():.4f} SI\")\nprint(f\"Δρ: {density_true.min():.2f} – {density_true.max():.2f} g/cc\")\nprint(f\"Cu: {Cu.min()*100:.2f}% – {Cu.max()*100:.2f}%\")"},"outputs":[{"name":"stdout","text":"Domain: 4000m × 4000m × 1000m\nCells: 2048\nχ:  0.0010 – 0.0235 SI\nΔρ: 0.00 – 0.23 g/cc\nCu: 0.50% – 1.40%\n","output_type":"stream"}],"source":"from simpeg import maps\nfrom simpeg.potential_fields import magnetics, gravity\nfrom discretize import TensorMesh\n\n# 3D mesh: 4km × 4km × 1km deep\nnx, ny, nz = 16, 16, 8\ndx, dy, dz = 250, 250, 125\nmesh = TensorMesh(\n    [np.ones(nx)*dx, np.ones(ny)*dy, np.ones(nz)*dz],\n    origin=[0, 0, -nz*dz]\n)\nn_cells = mesh.nC\ncc = mesh.cell_centers\n\nprint(f\"Domain: {nx*dx}m × {ny*dy}m × {nz*dz}m\")\nprint(f\"Cells: {n_cells}\")\n\n# Two mineralized bodies: Cu-Ni sulfide lenses\nd1 = np.sqrt(((cc[:,0]-1500)/400)**2 + ((cc[:,1]-1500)/350)**2 + ((cc[:,2]+500)/150)**2)\nbody1 = np.exp(-d1**2 * 2)\n\nd2 = np.sqrt(((cc[:,0]-2800)/350)**2 + ((cc[:,1]-2500)/300)**2 + ((cc[:,2]+700)/120)**2)\nbody2 = np.exp(-d2**2 * 2)\n\n# Magnetic susceptibility (SI) — sulfides are moderately magnetic\nsusceptibility_true = 0.001 + body1 * 0.05 + body2 * 0.02\n\n# Density contrast (g/cc) — massive sulfides are denser than host rock\ndensity_true = 0.0 + body1 * 0.5 + body2 * 0.3\n\n# Mineral compositions (mass fractions)\nCu = 0.005 + body1 * 0.02 + body2 * 0.01\nNi = 0.003 + body1 * 0.01 + body2 * 0.025\nCo = 0.001 + body1 * 0.005 + body2 * 0.012\ngangue = 1 - Cu - Ni - Co\ncompositions = np.stack([Cu, Ni, Co, gangue], axis=1)\n\nprint(f\"χ:  {susceptibility_true.min():.4f} – {susceptibility_true.max():.4f} SI\")\nprint(f\"Δρ: {density_true.min():.2f} – {density_true.max():.2f} g/cc\")\nprint(f\"Cu: {Cu.min()*100:.2f}% – {Cu.max()*100:.2f}%\")"},{"block_group":"85f682fce5d1469e8ba1cb0caee7a2ca","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"45cb2ba143f5407db37d651bdd519481","deepnote_block_group":"85f682fce5d1469e8ba1cb0caee7a2ca","deepnote_cell_type":"text-cell-h3","deepnote_sorting_key":"6","deepnote_source":"Compute the ilrs"},"source":"### Compute the ilrs"},{"block_group":"f55e5502e4764ba4bb1706844a978e97","cell_type":"code","execution_count":18,"metadata":{"execution_start":1770257028172,"execution_millis":2,"source_hash":"b59dfdee","execution_context_id":"a3ebaa0d-42ee-47b9-ad2b-cdae02ced48a","cell_id":"132303a11ca04c4bbc0fda0f3e839079","deepnote_block_group":"f55e5502e4764ba4bb1706844a978e97","deepnote_cell_type":"code","deepnote_sorting_key":"7","deepnote_content_hash":"b59dfdee","deepnote_execution_started_at":"2026-02-05T02:03:48.172Z","deepnote_execution_finished_at":"2026-02-05T02:03:48.174Z","deepnote_source":"import nuee\nsbp_helmert = np.array([\n    [1, 1, 1,-1],  # Cu, Ni, Co | Gangue\n    [1, 1,-1, 0],  # Cu, Ni | Co\n    [1,-1, 0, 0]   # Cu | Ni\n])\nbasis_ortho = nuee.composition.sbp_basis(sbp_helmert)\nilr_true = nuee.composition.ilr(compositions, basis=basis_ortho)\nprint(f\"ILR range: {ilr_true.min():.2f} – {ilr_true.max():.2f}\")"},"outputs":[{"name":"stdout","text":"ILR range: -5.19 – 1.11\n","output_type":"stream"}],"source":"import nuee\nsbp_helmert = np.array([\n    [1, 1, 1,-1],  # Cu, Ni, Co | Gangue\n    [1, 1,-1, 0],  # Cu, Ni | Co\n    [1,-1, 0, 0]   # Cu | Ni\n])\nbasis_ortho = nuee.composition.sbp_basis(sbp_helmert)\nilr_true = nuee.composition.ilr(compositions, basis=basis_ortho)\nprint(f\"ILR range: {ilr_true.min():.2f} – {ilr_true.max():.2f}\")"},{"block_group":"2358b2fd43c44c99b08c80d53a3c90af","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"6dd2d28999df4ddb81e608af604c33af","deepnote_block_group":"2358b2fd43c44c99b08c80d53a3c90af","deepnote_cell_type":"text-cell-h3","deepnote_sorting_key":"8","deepnote_source":"Define lithology"},"source":"### Define lithology"},{"block_group":"abeeed10470f466c806582fee0e19560","cell_type":"code","execution_count":21,"metadata":{"execution_start":1770257032335,"execution_millis":1,"source_hash":"3b40fed3","execution_context_id":"a3ebaa0d-42ee-47b9-ad2b-cdae02ced48a","cell_id":"2f593e2c83534a9e9222bf263ac5041a","deepnote_block_group":"abeeed10470f466c806582fee0e19560","deepnote_cell_type":"code","deepnote_sorting_key":"9","deepnote_content_hash":"3b40fed3","deepnote_execution_started_at":"2026-02-05T02:03:52.335Z","deepnote_execution_finished_at":"2026-02-05T02:03:52.336Z","deepnote_source":"def assign_lithology(body1_val, body2_val):\n    \"\"\"Assign lithological class based on ore body proximity.\"\"\"\n    intensity = max(body1_val, body2_val)\n    if intensity > 0.5:\n        return 'massive_sulfide'\n    elif intensity > 0.15:\n        return 'disseminated_sulfide'\n    elif intensity > 0.05:\n        return 'altered_gneiss'\n    else:\n        return 'fresh_gneiss'\n\nlithology_ids = {'fresh_gneiss': 0, 'altered_gneiss': 1,\n                 'disseminated_sulfide': 2, 'massive_sulfide': 3}\nn_lith = len(lithology_ids)\n\n# Assign lithology to every cell (for ground truth)\ncell_lithology = np.array([assign_lithology(body1[i], body2[i]) for i in range(n_cells)])\ncell_lith_id = np.array([lithology_ids[l] for l in cell_lithology])\n\nprint(\"Lithology counts:\")\nfor name, lid in lithology_ids.items():\n    count = (cell_lith_id == lid).sum()\n    print(f\"  {name:25s}: {count:4d} cells ({count/n_cells*100:.1f}%)\")"},"outputs":[{"name":"stdout","text":"Lithology counts:\n  fresh_gneiss             : 2014 cells (98.3%)\n  altered_gneiss           :   22 cells (1.1%)\n  disseminated_sulfide     :   10 cells (0.5%)\n  massive_sulfide          :    2 cells (0.1%)\n","output_type":"stream"}],"source":"def assign_lithology(body1_val, body2_val):\n    \"\"\"Assign lithological class based on ore body proximity.\"\"\"\n    intensity = max(body1_val, body2_val)\n    if intensity > 0.5:\n        return 'massive_sulfide'\n    elif intensity > 0.15:\n        return 'disseminated_sulfide'\n    elif intensity > 0.05:\n        return 'altered_gneiss'\n    else:\n        return 'fresh_gneiss'\n\nlithology_ids = {'fresh_gneiss': 0, 'altered_gneiss': 1,\n                 'disseminated_sulfide': 2, 'massive_sulfide': 3}\nn_lith = len(lithology_ids)\n\n# Assign lithology to every cell (for ground truth)\ncell_lithology = np.array([assign_lithology(body1[i], body2[i]) for i in range(n_cells)])\ncell_lith_id = np.array([lithology_ids[l] for l in cell_lithology])\n\nprint(\"Lithology counts:\")\nfor name, lid in lithology_ids.items():\n    count = (cell_lith_id == lid).sum()\n    print(f\"  {name:25s}: {count:4d} cells ({count/n_cells*100:.1f}%)\")"},{"block_group":"8db45a2a52b94d47aeddace61e841811","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"140dd5f4fce7493fa760d46d40611bde","deepnote_block_group":"8db45a2a52b94d47aeddace61e841811","deepnote_cell_type":"text-cell-h2","deepnote_sorting_key":"10","deepnote_source":"Multi-Sensor Surveys"},"source":"## Multi\\-Sensor Surveys"},{"block_group":"f7c71386f1354605a71cbc628cd16be7","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"16837d5929904858a886ca02431a805e","deepnote_block_group":"f7c71386f1354605a71cbc628cd16be7","deepnote_cell_type":"text-cell-h3","deepnote_sorting_key":"11","deepnote_source":"Airborne Magnetic Survey (TMI)"},"source":"### Airborne Magnetic Survey \\(TMI\\)"},{"block_group":"3dc376120e5f4deebff99db831a20837","cell_type":"code","execution_count":24,"metadata":{"execution_start":1770257035130,"execution_millis":270,"source_hash":"928efa90","execution_context_id":"a3ebaa0d-42ee-47b9-ad2b-cdae02ced48a","cell_id":"69a4c27634ab407db9313194198aa948","deepnote_block_group":"3dc376120e5f4deebff99db831a20837","deepnote_cell_type":"code","deepnote_sorting_key":"12","deepnote_content_hash":"928efa90","deepnote_execution_started_at":"2026-02-05T02:03:55.130Z","deepnote_execution_finished_at":"2026-02-05T02:03:55.400Z","deepnote_source":"rng_np = np.random.default_rng(42)\n\nn_stations_mag = 20\nsx_mag = np.linspace(200, nx*dx-200, n_stations_mag)\nsy_mag = np.linspace(200, ny*dy-200, n_stations_mag)\nstations_mag = np.array([[x, y, 80.0] for x in sx_mag for y in sy_mag])\n\nreceivers_mag = magnetics.receivers.Point(stations_mag, components='tmi')\nsource_mag = magnetics.sources.UniformBackgroundField(\n    receiver_list=[receivers_mag],\n    amplitude=55000, inclination=70, declination=0\n)\nsurvey_mag = magnetics.Survey(source_mag)\n\nsim_mag = magnetics.Simulation3DIntegral(\n    mesh=mesh, survey=survey_mag,\n    chiMap=maps.IdentityMap(mesh),\n    active_cells=np.ones(n_cells, dtype=bool),\n    store_sensitivities='ram'\n)\n\nmag_observed = sim_mag.dpred(susceptibility_true) + rng_np.normal(0, 1.5, len(stations_mag))\nG_mag_np = sim_mag.G\nG_mag = torch.tensor(G_mag_np, dtype=torch.float32)\n\nprint(f\"Magnetic TMI: {mag_observed.min():.1f} – {mag_observed.max():.1f} nT\")\nprint(f\"G_mag shape: {G_mag.shape}\")"},"outputs":[{"name":"stdout","text":"Magnetic TMI: -0.8 – 63.7 nT\nG_mag shape: torch.Size([400, 2048])\n","output_type":"stream"}],"source":"rng_np = np.random.default_rng(42)\n\nn_stations_mag = 20\nsx_mag = np.linspace(200, nx*dx-200, n_stations_mag)\nsy_mag = np.linspace(200, ny*dy-200, n_stations_mag)\nstations_mag = np.array([[x, y, 80.0] for x in sx_mag for y in sy_mag])\n\nreceivers_mag = magnetics.receivers.Point(stations_mag, components='tmi')\nsource_mag = magnetics.sources.UniformBackgroundField(\n    receiver_list=[receivers_mag],\n    amplitude=55000, inclination=70, declination=0\n)\nsurvey_mag = magnetics.Survey(source_mag)\n\nsim_mag = magnetics.Simulation3DIntegral(\n    mesh=mesh, survey=survey_mag,\n    chiMap=maps.IdentityMap(mesh),\n    active_cells=np.ones(n_cells, dtype=bool),\n    store_sensitivities='ram'\n)\n\nmag_observed = sim_mag.dpred(susceptibility_true) + rng_np.normal(0, 1.5, len(stations_mag))\nG_mag_np = sim_mag.G\nG_mag = torch.tensor(G_mag_np, dtype=torch.float32)\n\nprint(f\"Magnetic TMI: {mag_observed.min():.1f} – {mag_observed.max():.1f} nT\")\nprint(f\"G_mag shape: {G_mag.shape}\")"},{"block_group":"1c024bf1d47147aba8b78e9cab773ffc","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"53350a99d2b44ea8a06e0a20891b4017","deepnote_block_group":"1c024bf1d47147aba8b78e9cab773ffc","deepnote_cell_type":"text-cell-h3","deepnote_sorting_key":"13","deepnote_source":"Ground Gravity Survey (gz)"},"source":"### Ground Gravity Survey \\(gz\\)"},{"block_group":"54c5952c52cd4148bdb6199d91108b9b","cell_type":"code","execution_count":27,"metadata":{"execution_start":1770257037632,"execution_millis":266,"source_hash":"b487a7d8","execution_context_id":"a3ebaa0d-42ee-47b9-ad2b-cdae02ced48a","cell_id":"129f99f164474c569d18090841c413c4","deepnote_block_group":"54c5952c52cd4148bdb6199d91108b9b","deepnote_cell_type":"code","deepnote_sorting_key":"14","deepnote_content_hash":"b487a7d8","deepnote_execution_started_at":"2026-02-05T02:03:57.632Z","deepnote_execution_finished_at":"2026-02-05T02:03:57.898Z","deepnote_source":"stations_grav = np.array([[x, y, 1.0] for x in sx_mag for y in sy_mag])\n\nreceivers_grav = gravity.receivers.Point(stations_grav, components='gz')\nsource_grav = gravity.sources.SourceField(receiver_list=[receivers_grav])\nsurvey_grav = gravity.survey.Survey(source_field=source_grav)\n\nsim_grav = gravity.Simulation3DIntegral(\n    mesh=mesh, survey=survey_grav,\n    rhoMap=maps.IdentityMap(mesh),\n    active_cells=np.ones(n_cells, dtype=bool),\n    store_sensitivities='ram'\n)\n\ngrav_observed = sim_grav.dpred(density_true) + rng_np.normal(0, 0.02, len(stations_grav))\nG_grav_np = sim_grav.G\nG_grav = torch.tensor(G_grav_np, dtype=torch.float32)\n\nprint(f\"Gravity gz: {grav_observed.min():.3f} – {grav_observed.max():.3f} mGal\")"},"outputs":[{"name":"stdout","text":"Gravity gz: -0.433 – 0.045 mGal\n","output_type":"stream"}],"source":"stations_grav = np.array([[x, y, 1.0] for x in sx_mag for y in sy_mag])\n\nreceivers_grav = gravity.receivers.Point(stations_grav, components='gz')\nsource_grav = gravity.sources.SourceField(receiver_list=[receivers_grav])\nsurvey_grav = gravity.survey.Survey(source_field=source_grav)\n\nsim_grav = gravity.Simulation3DIntegral(\n    mesh=mesh, survey=survey_grav,\n    rhoMap=maps.IdentityMap(mesh),\n    active_cells=np.ones(n_cells, dtype=bool),\n    store_sensitivities='ram'\n)\n\ngrav_observed = sim_grav.dpred(density_true) + rng_np.normal(0, 0.02, len(stations_grav))\nG_grav_np = sim_grav.G\nG_grav = torch.tensor(G_grav_np, dtype=torch.float32)\n\nprint(f\"Gravity gz: {grav_observed.min():.3f} – {grav_observed.max():.3f} mGal\")"},{"block_group":"b9316513aef94edcb76ec733fad8dceb","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"ca76a9e89c1f4ba9bb8fa0ef182bb543","deepnote_block_group":"b9316513aef94edcb76ec733fad8dceb","deepnote_cell_type":"text-cell-h3","deepnote_sorting_key":"15","deepnote_source":"Hyperspectral Drone Survey"},"source":"### Hyperspectral Drone Survey"},{"block_group":"82677e88f8bf4044baeaacdd31041c40","cell_type":"code","execution_count":30,"metadata":{"execution_start":1770257040008,"execution_millis":2,"source_hash":"5fb8853c","execution_context_id":"a3ebaa0d-42ee-47b9-ad2b-cdae02ced48a","cell_id":"f3c6df669e304fb5aac62ff48a61f362","deepnote_block_group":"82677e88f8bf4044baeaacdd31041c40","deepnote_cell_type":"code","deepnote_sorting_key":"16","deepnote_content_hash":"5fb8853c","deepnote_execution_started_at":"2026-02-05T02:04:00.008Z","deepnote_execution_finished_at":"2026-02-05T02:04:00.010Z","deepnote_source":"surface_xx, surface_yy = np.meshgrid(mesh.cell_centers_x, mesh.cell_centers_y)\n\nd1_surf = np.sqrt(((surface_xx - 1500)/600)**2 + ((surface_yy - 1500)/550)**2)\nbody1_surf = np.exp(-d1_surf**2 * 1.5) * 0.4\n\nd2_surf = np.sqrt(((surface_xx - 2800)/550)**2 + ((surface_yy - 2500)/500)**2)\nbody2_surf = np.exp(-d2_surf**2 * 1.5) * 0.25\n\nn_bands = 10\nendmember_bg = np.array([0.30, 0.32, 0.35, 0.33, 0.30, 0.28, 0.25, 0.27, 0.30, 0.28])\nendmember_fe = np.array([0.15, 0.22, 0.38, 0.55, 0.68, 0.62, 0.48, 0.42, 0.38, 0.33])\nendmember_clay = np.array([0.40, 0.45, 0.50, 0.52, 0.58, 0.50, 0.40, 0.28, 0.18, 0.22])\n\nfrac_fe = body1_surf + 0.5 * body2_surf\nfrac_clay = 0.5 * body1_surf + body2_surf\nfrac_bg = np.clip(1.0 - frac_fe - frac_clay, 0.1, 1.0)\ntotal = frac_bg + frac_fe + frac_clay\nfrac_bg /= total; frac_fe /= total; frac_clay /= total\n\nhyper_image = (frac_bg[:,:,None] * endmember_bg +\n               frac_fe[:,:,None] * endmember_fe +\n               frac_clay[:,:,None] * endmember_clay)\nhyper_image += rng_np.normal(0, 0.02, hyper_image.shape)\nhyper_image = np.clip(hyper_image, 0, 1)\n\nprint(f\"Hyperspectral image: {hyper_image.shape}\")"},"outputs":[{"name":"stdout","text":"Hyperspectral image: (16, 16, 10)\n","output_type":"stream"}],"source":"surface_xx, surface_yy = np.meshgrid(mesh.cell_centers_x, mesh.cell_centers_y)\n\nd1_surf = np.sqrt(((surface_xx - 1500)/600)**2 + ((surface_yy - 1500)/550)**2)\nbody1_surf = np.exp(-d1_surf**2 * 1.5) * 0.4\n\nd2_surf = np.sqrt(((surface_xx - 2800)/550)**2 + ((surface_yy - 2500)/500)**2)\nbody2_surf = np.exp(-d2_surf**2 * 1.5) * 0.25\n\nn_bands = 10\nendmember_bg = np.array([0.30, 0.32, 0.35, 0.33, 0.30, 0.28, 0.25, 0.27, 0.30, 0.28])\nendmember_fe = np.array([0.15, 0.22, 0.38, 0.55, 0.68, 0.62, 0.48, 0.42, 0.38, 0.33])\nendmember_clay = np.array([0.40, 0.45, 0.50, 0.52, 0.58, 0.50, 0.40, 0.28, 0.18, 0.22])\n\nfrac_fe = body1_surf + 0.5 * body2_surf\nfrac_clay = 0.5 * body1_surf + body2_surf\nfrac_bg = np.clip(1.0 - frac_fe - frac_clay, 0.1, 1.0)\ntotal = frac_bg + frac_fe + frac_clay\nfrac_bg /= total; frac_fe /= total; frac_clay /= total\n\nhyper_image = (frac_bg[:,:,None] * endmember_bg +\n               frac_fe[:,:,None] * endmember_fe +\n               frac_clay[:,:,None] * endmember_clay)\nhyper_image += rng_np.normal(0, 0.02, hyper_image.shape)\nhyper_image = np.clip(hyper_image, 0, 1)\n\nprint(f\"Hyperspectral image: {hyper_image.shape}\")"},{"block_group":"92cbbf1dcfa54854b0da063005a0000f","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"be643a82ce6948ce8ea3c874f572c66f","deepnote_block_group":"92cbbf1dcfa54854b0da063005a0000f","deepnote_cell_type":"text-cell-h3","deepnote_sorting_key":"17","deepnote_source":"Surface soil geochemistry, gridded"},"source":"### Surface soil geochemistry, gridded"},{"block_group":"455fd495028a44eb986cb7831c65b5cb","cell_type":"code","execution_count":33,"metadata":{"execution_start":1770257042436,"execution_millis":0,"source_hash":"955f1246","execution_context_id":"a3ebaa0d-42ee-47b9-ad2b-cdae02ced48a","cell_id":"8483994f9b91449f9b3034740f69c269","deepnote_block_group":"455fd495028a44eb986cb7831c65b5cb","deepnote_cell_type":"code","deepnote_sorting_key":"18","deepnote_content_hash":"955f1246","deepnote_execution_started_at":"2026-02-05T02:04:02.436Z","deepnote_execution_finished_at":"2026-02-05T02:04:02.436Z","deepnote_source":"n_soil = 50\nsoil_x = rng_np.uniform(200, nx*dx-200, n_soil)\nsoil_y = rng_np.uniform(200, ny*dy-200, n_soil)\n\nd1_soil = np.sqrt(((soil_x - 1500)/600)**2 + ((soil_y - 1500)/550)**2)\nbody1_soil = np.exp(-d1_soil**2 * 1.5) * 0.4\nd2_soil = np.sqrt(((soil_x - 2800)/550)**2 + ((soil_y - 2500)/500)**2)\nbody2_soil = np.exp(-d2_soil**2 * 1.5) * 0.25\n\nCu_soil = np.clip(30 + body1_soil * 500 + body2_soil * 300 + rng_np.normal(0, 10, n_soil), 5, None)\nNi_soil = np.clip(20 + body1_soil * 200 + body2_soil * 600 + rng_np.normal(0, 8, n_soil), 5, None)\nCo_soil = np.clip(8 + body1_soil * 80 + body2_soil * 200 + rng_np.normal(0, 4, n_soil), 2, None)\nFe_soil = 3.0 + body1_soil * 5 + body2_soil * 3 + rng_np.normal(0, 0.3, n_soil)\nS_soil = 0.1 + body1_soil * 2 + body2_soil * 1.5 + rng_np.normal(0, 0.05, n_soil)\n\ngrid_xy = np.column_stack([surface_xx.ravel(), surface_yy.ravel()])\nsoil_points = np.column_stack([soil_x, soil_y])\n\ngeochem_grid = np.zeros((nx * ny, 5))\nfor i, vals in enumerate([Cu_soil, Ni_soil, Co_soil, Fe_soil, S_soil]):\n    grid_lin = griddata(soil_points, vals, grid_xy, method='linear')\n    grid_near = griddata(soil_points, vals, grid_xy, method='nearest')\n    geochem_grid[:, i] = np.where(np.isnan(grid_lin), grid_near, grid_lin)\n\ngeochem_min = geochem_grid.min(axis=0)\ngeochem_max = geochem_grid.max(axis=0)\ngeochem_grid_norm = (geochem_grid - geochem_min) / (geochem_max - geochem_min + 1e-8)\ngeochem_grid_2d = geochem_grid_norm.reshape(ny, nx, 5)"},"outputs":[],"source":"n_soil = 50\nsoil_x = rng_np.uniform(200, nx*dx-200, n_soil)\nsoil_y = rng_np.uniform(200, ny*dy-200, n_soil)\n\nd1_soil = np.sqrt(((soil_x - 1500)/600)**2 + ((soil_y - 1500)/550)**2)\nbody1_soil = np.exp(-d1_soil**2 * 1.5) * 0.4\nd2_soil = np.sqrt(((soil_x - 2800)/550)**2 + ((soil_y - 2500)/500)**2)\nbody2_soil = np.exp(-d2_soil**2 * 1.5) * 0.25\n\nCu_soil = np.clip(30 + body1_soil * 500 + body2_soil * 300 + rng_np.normal(0, 10, n_soil), 5, None)\nNi_soil = np.clip(20 + body1_soil * 200 + body2_soil * 600 + rng_np.normal(0, 8, n_soil), 5, None)\nCo_soil = np.clip(8 + body1_soil * 80 + body2_soil * 200 + rng_np.normal(0, 4, n_soil), 2, None)\nFe_soil = 3.0 + body1_soil * 5 + body2_soil * 3 + rng_np.normal(0, 0.3, n_soil)\nS_soil = 0.1 + body1_soil * 2 + body2_soil * 1.5 + rng_np.normal(0, 0.05, n_soil)\n\ngrid_xy = np.column_stack([surface_xx.ravel(), surface_yy.ravel()])\nsoil_points = np.column_stack([soil_x, soil_y])\n\ngeochem_grid = np.zeros((nx * ny, 5))\nfor i, vals in enumerate([Cu_soil, Ni_soil, Co_soil, Fe_soil, S_soil]):\n    grid_lin = griddata(soil_points, vals, grid_xy, method='linear')\n    grid_near = griddata(soil_points, vals, grid_xy, method='nearest')\n    geochem_grid[:, i] = np.where(np.isnan(grid_lin), grid_near, grid_lin)\n\ngeochem_min = geochem_grid.min(axis=0)\ngeochem_max = geochem_grid.max(axis=0)\ngeochem_grid_norm = (geochem_grid - geochem_min) / (geochem_max - geochem_min + 1e-8)\ngeochem_grid_2d = geochem_grid_norm.reshape(ny, nx, 5)"},{"block_group":"c5c2be97945246cfb785a70f9087c5f0","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"9e06761636b2415c9e4e4d3866d6b4e1","deepnote_block_group":"c5c2be97945246cfb785a70f9087c5f0","deepnote_cell_type":"text-cell-h3","deepnote_sorting_key":"19","deepnote_source":"Drill holes"},"source":"### Drill holes"},{"block_group":"26fb3a5a8e0643199dfd471a9ddaa73e","cell_type":"code","execution_count":39,"metadata":{"execution_start":1770257074606,"execution_millis":0,"source_hash":"ef62ac6c","execution_context_id":"a3ebaa0d-42ee-47b9-ad2b-cdae02ced48a","cell_id":"c8db74efb45f44979dd559576d0e3b39","deepnote_block_group":"26fb3a5a8e0643199dfd471a9ddaa73e","deepnote_cell_type":"code","deepnote_sorting_key":"20","deepnote_content_hash":"ef62ac6c","deepnote_execution_started_at":"2026-02-05T02:04:34.606Z","deepnote_execution_finished_at":"2026-02-05T02:04:34.606Z","deepnote_source":"hole_xy = [\n    (1500, 1500), (2800, 2500), (500, 500), (2000, 2000), (3500, 1000),\n    (1200, 1800), (2500, 2200), (1800, 2800), (3000, 1500), (800, 2500)\n]\n\nvalidation_holes = {'DH4', 'DH7'}\nnoise_rel = 0.05\n\nforages = []\nfor i, (hx, hy) in enumerate(hole_xy):\n    ix = np.argmin(np.abs(mesh.cell_centers_x - hx))\n    iy = np.argmin(np.abs(mesh.cell_centers_y - hy))\n    for iz in range(nz):\n        idx = ix + iy * nx + iz * nx * ny\n        cu_noisy = max(Cu[idx] * (1 + rng_np.normal(0, noise_rel)), 1e-6)\n        ni_noisy = max(Ni[idx] * (1 + rng_np.normal(0, noise_rel)), 1e-6)\n        co_noisy = max(Co[idx] * (1 + rng_np.normal(0, noise_rel)), 1e-6)\n        gangue_noisy = max(1 - cu_noisy - ni_noisy - co_noisy, 1e-6)\n        comp_noisy = np.array([[cu_noisy, ni_noisy, co_noisy, gangue_noisy]])\n        ilr_noisy = nuee.composition.ilr(comp_noisy, basis=basis_ortho)[0]\n\n        hole_name = f'DH{i+1}'\n        lith = cell_lithology[idx]\n        forages.append({\n            'hole': hole_name,\n            'x': mesh.cell_centers_x[ix], 'y': mesh.cell_centers_y[iy],\n            'z': mesh.cell_centers_z[iz],\n            'Cu': cu_noisy, 'Ni': ni_noisy, 'Co': co_noisy,\n            'ilr0': ilr_noisy[0], 'ilr1': ilr_noisy[1], 'ilr2': ilr_noisy[2],\n            'lithology': lith,\n            'lith_id': lithology_ids[lith],\n            'cell_idx': idx,\n            'is_validation': hole_name in validation_holes\n        })\n\ndf_forages = pd.DataFrame(forages)\ndf_train = df_forages[~df_forages['is_validation']].reset_index(drop=True)\ndf_val = df_forages[df_forages['is_validation']].reset_index(drop=True)\n\nprint(f\"Drill samples: {len(df_forages)} | train: {len(df_train)} | val: {len(df_val)}\")\nprint(f\"\\nLithology log (DH1):\")\ndh1 = df_forages[df_forages['hole'] == 'DH1'][['z', 'lithology', 'Cu']].reset_index(drop=True)\nfor _, row in dh1.iterrows():\n    print(f\"  z={row['z']:7.0f}m  {row['lithology']:25s}  Cu={row['Cu']*100:.2f}%\")"},"outputs":[{"name":"stdout","text":"Drill samples: 80 | train: 64 | val: 16\n\nLithology log (DH1):\n  z=   -938m  fresh_gneiss               Cu=0.49%\n  z=   -812m  fresh_gneiss               Cu=0.50%\n  z=   -688m  fresh_gneiss               Cu=0.53%\n  z=   -562m  disseminated_sulfide       Cu=1.43%\n  z=   -438m  disseminated_sulfide       Cu=1.45%\n  z=   -312m  fresh_gneiss               Cu=0.55%\n  z=   -188m  fresh_gneiss               Cu=0.52%\n  z=    -62m  fresh_gneiss               Cu=0.48%\n","output_type":"stream"}],"source":"hole_xy = [\n    (1500, 1500), (2800, 2500), (500, 500), (2000, 2000), (3500, 1000),\n    (1200, 1800), (2500, 2200), (1800, 2800), (3000, 1500), (800, 2500)\n]\n\nvalidation_holes = {'DH4', 'DH7'}\nnoise_rel = 0.05\n\nforages = []\nfor i, (hx, hy) in enumerate(hole_xy):\n    ix = np.argmin(np.abs(mesh.cell_centers_x - hx))\n    iy = np.argmin(np.abs(mesh.cell_centers_y - hy))\n    for iz in range(nz):\n        idx = ix + iy * nx + iz * nx * ny\n        cu_noisy = max(Cu[idx] * (1 + rng_np.normal(0, noise_rel)), 1e-6)\n        ni_noisy = max(Ni[idx] * (1 + rng_np.normal(0, noise_rel)), 1e-6)\n        co_noisy = max(Co[idx] * (1 + rng_np.normal(0, noise_rel)), 1e-6)\n        gangue_noisy = max(1 - cu_noisy - ni_noisy - co_noisy, 1e-6)\n        comp_noisy = np.array([[cu_noisy, ni_noisy, co_noisy, gangue_noisy]])\n        ilr_noisy = nuee.composition.ilr(comp_noisy, basis=basis_ortho)[0]\n\n        hole_name = f'DH{i+1}'\n        lith = cell_lithology[idx]\n        forages.append({\n            'hole': hole_name,\n            'x': mesh.cell_centers_x[ix], 'y': mesh.cell_centers_y[iy],\n            'z': mesh.cell_centers_z[iz],\n            'Cu': cu_noisy, 'Ni': ni_noisy, 'Co': co_noisy,\n            'ilr0': ilr_noisy[0], 'ilr1': ilr_noisy[1], 'ilr2': ilr_noisy[2],\n            'lithology': lith,\n            'lith_id': lithology_ids[lith],\n            'cell_idx': idx,\n            'is_validation': hole_name in validation_holes\n        })\n\ndf_forages = pd.DataFrame(forages)\ndf_train = df_forages[~df_forages['is_validation']].reset_index(drop=True)\ndf_val = df_forages[df_forages['is_validation']].reset_index(drop=True)\n\nprint(f\"Drill samples: {len(df_forages)} | train: {len(df_train)} | val: {len(df_val)}\")\nprint(f\"\\nLithology log (DH1):\")\ndh1 = df_forages[df_forages['hole'] == 'DH1'][['z', 'lithology', 'Cu']].reset_index(drop=True)\nfor _, row in dh1.iterrows():\n    print(f\"  z={row['z']:7.0f}m  {row['lithology']:25s}  Cu={row['Cu']*100:.2f}%\")"},{"block_group":"f16ed1405e9e4bc5b55e861832f32f67","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"399852a770c54c459935881a386f4aee","deepnote_block_group":"f16ed1405e9e4bc5b55e861832f32f67","deepnote_cell_type":"text-cell-h2","deepnote_sorting_key":"21","deepnote_source":"GemPy structural model"},"source":"## GemPy structural model"},{"block_group":"c6955cd525fd4faab7921bdd9adddd4e","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":182,"fromCodePoint":177},{"type":"marks","marks":{"bold":true},"toCodePoint":242,"fromCodePoint":238}],"cell_id":"85945f1b2b694571be52ef4a80f71670","deepnote_block_group":"c6955cd525fd4faab7921bdd9adddd4e","deepnote_cell_type":"text-cell-p","deepnote_sorting_key":"22","deepnote_source":"GemPy interpolates a scalar potential field φ(x,y,z) that defines the geological unit boundaries. This scalar field becomes an input to our NeRF decoders — it tells the network where geological boundaries are, so the network can focus on what properties exist within each unit."},"source":"GemPy interpolates a scalar potential field φ\\(x,y,z\\) that defines the geological unit boundaries\\. This scalar field becomes an input to our NeRF decoders — it tells the network where geological boundaries are, so the network can focus on what properties exist within each unit\\."},{"block_group":"05e42ebf7753436883d75ed3e7f503dc","cell_type":"code","execution_count":42,"metadata":{"execution_start":1770257081344,"execution_millis":607,"source_hash":"db88c006","execution_context_id":"a3ebaa0d-42ee-47b9-ad2b-cdae02ced48a","cell_id":"08d8f29f808b40ccafe2cf6b2b7a2d5f","deepnote_block_group":"05e42ebf7753436883d75ed3e7f503dc","deepnote_cell_type":"code","deepnote_sorting_key":"23","deepnote_content_hash":"db88c006","deepnote_execution_started_at":"2026-02-05T02:04:41.344Z","deepnote_execution_finished_at":"2026-02-05T02:04:41.951Z","deepnote_source":"# Extract contact points from drill holes: locations where lithology changes\ncontacts = []\norientations_data = []\n\nfor hole_name in df_forages['hole'].unique():\n    dh = df_forages[df_forages['hole'] == hole_name].sort_values('z', ascending=False)\n    rows = dh.reset_index(drop=True)\n\n    for j in range(len(rows) - 1):\n        if rows.loc[j, 'lith_id'] != rows.loc[j+1, 'lith_id']:\n            # Contact midpoint between the two intervals\n            cx = float(rows.loc[j, 'x'])\n            cy = float(rows.loc[j, 'y'])\n            cz = float((rows.loc[j, 'z'] + rows.loc[j+1, 'z']) / 2)\n            contacts.append({\n                'x': cx, 'y': cy, 'z': cz,\n                'surface': 'ore_contact'\n            })\n\n# Need at least a few points. Add surface reference points (host rock at surface)\nfor x_ref in [500, 2000, 3500]:\n    for y_ref in [500, 2000, 3500]:\n        contacts.append({'x': float(x_ref), 'y': float(y_ref), 'z': -62.5,\n                         'surface': 'surface_ref'})\n\ndf_contacts = pd.DataFrame(contacts)\nprint(f\"Contact points extracted: {len(df_contacts)}\")\nprint(f\"  ore_contact: {(df_contacts['surface']=='ore_contact').sum()}\")\nprint(f\"  surface_ref: {(df_contacts['surface']=='surface_ref').sum()}\")\n\n# %%\n# Build GemPy model\ngeo_model = gp.create_geomodel(\n    project_name='sulfide_exploration',\n    extent=[0, 4000, 0, 4000, -1000, 0],\n    resolution=[16, 16, 8],\n    structural_frame=StructuralFrame.initialize_default_structure()\n)\n\n# Add surface contact points\nore_contacts = df_contacts[df_contacts['surface'] == 'ore_contact']\nif len(ore_contacts) > 0:\n    gp.add_surface_points(\n        geo_model,\n        x=ore_contacts['x'].tolist(),\n        y=ore_contacts['y'].tolist(),\n        z=ore_contacts['z'].tolist(),\n        elements_names=['surface1'] * len(ore_contacts)\n    )\n\n# Add orientations (vertical for our case — bodies are roughly horizontal lenses)\n# In reality, a geologist would estimate these from core and structural measurements\ngp.add_orientations(\n    geo_model,\n    x=[1500.0, 2800.0],\n    y=[1500.0, 2500.0],\n    z=[-500.0, -700.0],\n    elements_names=['surface1', 'surface1'],\n    pole_vector=[[0, 0, 1], [0, 0, 1]]\n)\n\ngeo_model.update_transform()\n\n# Compute structural model\nprint(\"Computing GemPy structural model...\")\nsol = gp.compute_model(geo_model)\nprint(\"GemPy model computed.\")\n\n# %%\n# Extract scalar field at all cell centers using custom grid\ngp.set_custom_grid(geo_model.grid, cc.astype(np.float64))\nsol = gp.compute_model(geo_model)\n\n# Get scalar field values from the octree output\noo0 = sol.octrees_output[0]\ngc0 = oo0.grid_centers\noc0 = oo0.output_centers\nef0 = oc0.exported_fields\n\ncustom_slice = gc0.custom_grid_slice\nscalar_field_at_cells = np.array(ef0.scalar_field[custom_slice])\n\n# Normalize scalar field to [0, 1] for use as network input\nsf_min, sf_max = scalar_field_at_cells.min(), scalar_field_at_cells.max()\nif sf_max > sf_min:\n    scalar_field_norm = (scalar_field_at_cells - sf_min) / (sf_max - sf_min)\nelse:\n    scalar_field_norm = np.zeros_like(scalar_field_at_cells)\n\nprint(f\"Scalar field: {scalar_field_at_cells.min():.4f} – {scalar_field_at_cells.max():.4f}\")\nprint(f\"Normalized:   {scalar_field_norm.min():.4f} – {scalar_field_norm.max():.4f}\")\n\n# Get lithology IDs from GemPy\ngempy_lith_ids = np.array(oc0.ids_custom_grid, dtype=np.int32)\nprint(f\"GemPy lithology IDs: unique = {np.unique(gempy_lith_ids)}\")"},"outputs":[{"name":"stdout","text":"Contact points extracted: 14\n  ore_contact: 5\n  surface_ref: 9\nComputing GemPy structural model...\nSetting Backend To: AvailableBackends.numpy\n/root/venv/lib/python3.13/site-packages/gempy_engine/modules/activator/_soft_segment.py:95: RuntimeWarning: overflow encountered in exp\n  return 1.0 / (1.0 + bt.t.exp(x))\nGemPy model computed.\nActive grids: GridTypes.DENSE|CUSTOM|NONE\nSetting Backend To: AvailableBackends.numpy\n/root/venv/lib/python3.13/site-packages/gempy_engine/modules/activator/_soft_segment.py:95: RuntimeWarning: overflow encountered in exp\n  return 1.0 / (1.0 + bt.t.exp(x))\nScalar field: -0.2666 – 0.2318\nNormalized:   0.0000 – 1.0000\nGemPy lithology IDs: unique = [1 2]\n","output_type":"stream"}],"source":"# Extract contact points from drill holes: locations where lithology changes\ncontacts = []\norientations_data = []\n\nfor hole_name in df_forages['hole'].unique():\n    dh = df_forages[df_forages['hole'] == hole_name].sort_values('z', ascending=False)\n    rows = dh.reset_index(drop=True)\n\n    for j in range(len(rows) - 1):\n        if rows.loc[j, 'lith_id'] != rows.loc[j+1, 'lith_id']:\n            # Contact midpoint between the two intervals\n            cx = float(rows.loc[j, 'x'])\n            cy = float(rows.loc[j, 'y'])\n            cz = float((rows.loc[j, 'z'] + rows.loc[j+1, 'z']) / 2)\n            contacts.append({\n                'x': cx, 'y': cy, 'z': cz,\n                'surface': 'ore_contact'\n            })\n\n# Need at least a few points. Add surface reference points (host rock at surface)\nfor x_ref in [500, 2000, 3500]:\n    for y_ref in [500, 2000, 3500]:\n        contacts.append({'x': float(x_ref), 'y': float(y_ref), 'z': -62.5,\n                         'surface': 'surface_ref'})\n\ndf_contacts = pd.DataFrame(contacts)\nprint(f\"Contact points extracted: {len(df_contacts)}\")\nprint(f\"  ore_contact: {(df_contacts['surface']=='ore_contact').sum()}\")\nprint(f\"  surface_ref: {(df_contacts['surface']=='surface_ref').sum()}\")\n\n# %%\n# Build GemPy model\ngeo_model = gp.create_geomodel(\n    project_name='sulfide_exploration',\n    extent=[0, 4000, 0, 4000, -1000, 0],\n    resolution=[16, 16, 8],\n    structural_frame=StructuralFrame.initialize_default_structure()\n)\n\n# Add surface contact points\nore_contacts = df_contacts[df_contacts['surface'] == 'ore_contact']\nif len(ore_contacts) > 0:\n    gp.add_surface_points(\n        geo_model,\n        x=ore_contacts['x'].tolist(),\n        y=ore_contacts['y'].tolist(),\n        z=ore_contacts['z'].tolist(),\n        elements_names=['surface1'] * len(ore_contacts)\n    )\n\n# Add orientations (vertical for our case — bodies are roughly horizontal lenses)\n# In reality, a geologist would estimate these from core and structural measurements\ngp.add_orientations(\n    geo_model,\n    x=[1500.0, 2800.0],\n    y=[1500.0, 2500.0],\n    z=[-500.0, -700.0],\n    elements_names=['surface1', 'surface1'],\n    pole_vector=[[0, 0, 1], [0, 0, 1]]\n)\n\ngeo_model.update_transform()\n\n# Compute structural model\nprint(\"Computing GemPy structural model...\")\nsol = gp.compute_model(geo_model)\nprint(\"GemPy model computed.\")\n\n# %%\n# Extract scalar field at all cell centers using custom grid\ngp.set_custom_grid(geo_model.grid, cc.astype(np.float64))\nsol = gp.compute_model(geo_model)\n\n# Get scalar field values from the octree output\noo0 = sol.octrees_output[0]\ngc0 = oo0.grid_centers\noc0 = oo0.output_centers\nef0 = oc0.exported_fields\n\ncustom_slice = gc0.custom_grid_slice\nscalar_field_at_cells = np.array(ef0.scalar_field[custom_slice])\n\n# Normalize scalar field to [0, 1] for use as network input\nsf_min, sf_max = scalar_field_at_cells.min(), scalar_field_at_cells.max()\nif sf_max > sf_min:\n    scalar_field_norm = (scalar_field_at_cells - sf_min) / (sf_max - sf_min)\nelse:\n    scalar_field_norm = np.zeros_like(scalar_field_at_cells)\n\nprint(f\"Scalar field: {scalar_field_at_cells.min():.4f} – {scalar_field_at_cells.max():.4f}\")\nprint(f\"Normalized:   {scalar_field_norm.min():.4f} – {scalar_field_norm.max():.4f}\")\n\n# Get lithology IDs from GemPy\ngempy_lith_ids = np.array(oc0.ids_custom_grid, dtype=np.int32)\nprint(f\"GemPy lithology IDs: unique = {np.unique(gempy_lith_ids)}\")"},{"block_group":"86d8ee31de8f407ea0ac4cd563d15b70","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"9e26d6cfcb6147e1b42d211d3c01bdca","deepnote_block_group":"86d8ee31de8f407ea0ac4cd563d15b70","deepnote_cell_type":"text-cell-h2","deepnote_sorting_key":"24","deepnote_source":"Differentiable Forward Models"},"source":"## Differentiable Forward Models"},{"block_group":"e594b678dfe84683917cf0f8582759ba","cell_type":"code","execution_count":45,"metadata":{"execution_start":1770257085063,"execution_millis":1,"source_hash":"4ec52f32","execution_context_id":"a3ebaa0d-42ee-47b9-ad2b-cdae02ced48a","cell_id":"7200d4f0981f4306b0a11d528be4a5bc","deepnote_block_group":"e594b678dfe84683917cf0f8582759ba","deepnote_cell_type":"code","deepnote_sorting_key":"25","deepnote_content_hash":"4ec52f32","deepnote_execution_started_at":"2026-02-05T02:04:45.063Z","deepnote_execution_finished_at":"2026-02-05T02:04:45.064Z","deepnote_source":"def forward_magnetic(susceptibility):\n    \"\"\"Forward APPROXIMATED magnetics: TMI = G_mag @ χ\"\"\"\n    return G_mag @ susceptibility\n\ndef forward_gravity(density):\n    \"\"\"Forward gravity: gz = G_grav @ Δρ\"\"\"\n    return G_grav @ density"},"outputs":[],"source":"def forward_magnetic(susceptibility):\n    \"\"\"Forward APPROXIMATED magnetics: TMI = G_mag @ χ\"\"\"\n    return G_mag @ susceptibility\n\ndef forward_gravity(density):\n    \"\"\"Forward gravity: gz = G_grav @ Δρ\"\"\"\n    return G_grav @ density"},{"block_group":"ae476ddec18a42b487e212b95a55be59","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"c6487f6e480146f6b2743b876d28bae3","deepnote_block_group":"ae476ddec18a42b487e212b95a55be59","deepnote_cell_type":"text-cell-h2","deepnote_sorting_key":"26","deepnote_source":"Network Architecture"},"source":"## Network Architecture"},{"block_group":"341102d803624ae0a33f50a6343421e1","cell_type":"code","execution_count":51,"metadata":{"execution_start":1770257093228,"execution_millis":1,"source_hash":"ad3d22c8","execution_context_id":"a3ebaa0d-42ee-47b9-ad2b-cdae02ced48a","cell_id":"ea8546fd614f4e1d9cec5a614bbcd0a9","deepnote_block_group":"341102d803624ae0a33f50a6343421e1","deepnote_cell_type":"code","deepnote_sorting_key":"27","deepnote_content_hash":"ad3d22c8","deepnote_execution_started_at":"2026-02-05T02:04:53.228Z","deepnote_execution_finished_at":"2026-02-05T02:04:53.229Z","deepnote_source":"class MultiModalEncoder(nn.Module):\n    \"\"\"\n    Fuses magnetic, gravity, hyperspectral, and geochemistry inputs\n    into a shared latent vector.\n    \"\"\"\n    def __init__(self, latent_dim=32, n_mag=20, n_hyper_bands=10):\n        super().__init__()\n        self.latent_dim = latent_dim\n\n        # Magnetic branch: (1, 20, 20) → 64\n        self.mag_conv1 = nn.Conv2d(1, 16, 3, padding=1)\n        self.mag_conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        self.mag_fc = nn.Linear(32 * n_mag * n_mag, 64)\n\n        # Gravity branch: (1, 20, 20) → 64\n        self.grav_conv1 = nn.Conv2d(1, 16, 3, padding=1)\n        self.grav_conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        self.grav_fc = nn.Linear(32 * n_mag * n_mag, 64)\n\n        # Hyperspectral branch: (10, 16, 16) → 64\n        self.hyper_conv1 = nn.Conv2d(n_hyper_bands, 16, 3, padding=1)\n        self.hyper_conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        self.hyper_fc = nn.Linear(32 * 16 * 16, 64)\n\n        # Geochemistry branch: (5, 16, 16) → 32\n        self.geochem_conv = nn.Conv2d(5, 16, 3, padding=1)\n        self.geochem_fc = nn.Linear(16 * 16 * 16, 32)\n\n        # Fusion MLP: 224 → 128 → 64 → latent\n        self.fusion = nn.Sequential(\n            nn.Linear(224, 128), nn.ReLU(),\n            nn.Linear(128, 64), nn.ReLU(),\n        )\n        self.mu_head = nn.Linear(64, latent_dim)\n        self.logvar_head = nn.Linear(64, latent_dim)\n\n    def forward(self, mag_grid, grav_grid, hyper_img, geochem_grid):\n        # mag_grid: (20, 20) → (1, 1, 20, 20)\n        m = F.gelu(self.mag_conv1(mag_grid.unsqueeze(0).unsqueeze(0)))\n        m = F.gelu(self.mag_conv2(m))\n        m = F.gelu(self.mag_fc(m.flatten()))\n\n        g = F.gelu(self.grav_conv1(grav_grid.unsqueeze(0).unsqueeze(0)))\n        g = F.gelu(self.grav_conv2(g))\n        g = F.gelu(self.grav_fc(g.flatten()))\n\n        # hyper_img: (16, 16, 10) → (1, 10, 16, 16)\n        h = hyper_img.permute(2, 0, 1).unsqueeze(0)\n        h = F.gelu(self.hyper_conv1(h))\n        h = F.gelu(self.hyper_conv2(h))\n        h = F.gelu(self.hyper_fc(h.flatten()))\n\n        # geochem: (16, 16, 5) → (1, 5, 16, 16)\n        c = geochem_grid.permute(2, 0, 1).unsqueeze(0)\n        c = F.gelu(self.geochem_conv(c))\n        c = F.gelu(self.geochem_fc(c.flatten()))\n\n        fused = torch.cat([m, g, h, c])  # 64+64+64+32 = 224\n        fused = self.fusion(fused)\n        return self.mu_head(fused), self.logvar_head(fused)\n\n\nclass DecoderSusceptibility(nn.Module):\n    \"\"\"\n    (latent, coord_norm, φ_gempy, unit_embedding) → χ_local.\n    GemPy scalar field provides geological structure awareness.\n    MC Dropout for Bayesian uncertainty.\n    \"\"\"\n    def __init__(self, latent_dim=32, n_units=4, embed_dim=4, dropout=0.1):\n        super().__init__()\n        self.unit_embed = nn.Embedding(n_units, embed_dim)\n        input_dim = latent_dim + 3 + 1 + embed_dim  # z + coord + φ + unit_emb\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 128), nn.GELU(), nn.Dropout(dropout),\n            nn.Linear(128, 64), nn.GELU(), nn.Dropout(dropout),\n            nn.Linear(64, 32), nn.GELU(),\n            nn.Linear(32, 1),\n        )\n\n    def forward(self, latent, coord, phi, unit_id):\n        \"\"\"\n        latent: (latent_dim,) or (N, latent_dim)\n        coord: (3,) or (N, 3)\n        phi: scalar or (N,)\n        unit_id: int or (N,) long tensor\n        \"\"\"\n        u_emb = self.unit_embed(unit_id)\n        if phi.dim() == 0:\n            phi = phi.unsqueeze(0)\n        if phi.dim() == 1 and latent.dim() == 1:\n            x = torch.cat([latent, coord, phi, u_emb])\n        else:\n            x = torch.cat([latent, coord, phi.unsqueeze(-1) if phi.dim() == 1 else phi, u_emb], dim=-1)\n        return F.softplus(self.net(x).squeeze(-1)) * 0.01\n\n\nclass DecoderDensity(nn.Module):\n    \"\"\"(latent, coord_norm, φ_gempy, unit_embedding) → Δρ_local.\"\"\"\n    def __init__(self, latent_dim=32, n_units=4, embed_dim=4, dropout=0.1):\n        super().__init__()\n        self.unit_embed = nn.Embedding(n_units, embed_dim)\n        input_dim = latent_dim + 3 + 1 + embed_dim\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 128), nn.GELU(), nn.Dropout(dropout),\n            nn.Linear(128, 64), nn.GELU(), nn.Dropout(dropout),\n            nn.Linear(64, 32), nn.GELU(),\n            nn.Linear(32, 1),\n        )\n\n    def forward(self, latent, coord, phi, unit_id):\n        u_emb = self.unit_embed(unit_id)\n        if phi.dim() == 0:\n            phi = phi.unsqueeze(0)\n        if phi.dim() == 1 and latent.dim() == 1:\n            x = torch.cat([latent, coord, phi, u_emb])\n        else:\n            x = torch.cat([latent, coord, phi.unsqueeze(-1) if phi.dim() == 1 else phi, u_emb], dim=-1)\n        return F.softplus(self.net(x).squeeze(-1)) * 0.1\n\n\nclass DecoderILR(nn.Module):\n    \"\"\"\n    (latent, coord, φ, unit_id, χ, ρ) → ILR compositions (3-dim).\n    Receives physical properties as inputs — bridges geophysics to geochemistry.\n    \"\"\"\n    def __init__(self, latent_dim=32, n_units=4, embed_dim=4, dropout=0.1):\n        super().__init__()\n        self.unit_embed = nn.Embedding(n_units, embed_dim)\n        input_dim = latent_dim + 3 + 1 + embed_dim + 2  # + chi_scaled + rho_scaled\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 64), nn.ReLU(), nn.Dropout(dropout),\n            nn.Linear(64, 32), nn.ReLU(), nn.Dropout(dropout),\n            nn.Linear(32, 3),\n        )\n\n    def forward(self, latent, coord, phi, unit_id, chi_local, rho_local):\n        u_emb = self.unit_embed(unit_id)\n        if phi.dim() == 0:\n            phi = phi.unsqueeze(0)\n\n        # Scale physical properties to similar magnitude as other inputs\n        chi_s = (chi_local * 100).unsqueeze(-1) if chi_local.dim() == 1 else (chi_local * 100)\n        rho_s = (rho_local * 10).unsqueeze(-1) if rho_local.dim() == 1 else (rho_local * 10)\n\n        if latent.dim() == 1:\n            x = torch.cat([latent, coord, phi, u_emb, chi_s, rho_s])\n        else:\n            x = torch.cat([latent, coord,\n                           phi.unsqueeze(-1) if phi.dim() == 1 else phi,\n                           u_emb, chi_s, rho_s], dim=-1)\n        return self.net(x)"},"outputs":[],"source":"class MultiModalEncoder(nn.Module):\n    \"\"\"\n    Fuses magnetic, gravity, hyperspectral, and geochemistry inputs\n    into a shared latent vector.\n    \"\"\"\n    def __init__(self, latent_dim=32, n_mag=20, n_hyper_bands=10):\n        super().__init__()\n        self.latent_dim = latent_dim\n\n        # Magnetic branch: (1, 20, 20) → 64\n        self.mag_conv1 = nn.Conv2d(1, 16, 3, padding=1)\n        self.mag_conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        self.mag_fc = nn.Linear(32 * n_mag * n_mag, 64)\n\n        # Gravity branch: (1, 20, 20) → 64\n        self.grav_conv1 = nn.Conv2d(1, 16, 3, padding=1)\n        self.grav_conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        self.grav_fc = nn.Linear(32 * n_mag * n_mag, 64)\n\n        # Hyperspectral branch: (10, 16, 16) → 64\n        self.hyper_conv1 = nn.Conv2d(n_hyper_bands, 16, 3, padding=1)\n        self.hyper_conv2 = nn.Conv2d(16, 32, 3, padding=1)\n        self.hyper_fc = nn.Linear(32 * 16 * 16, 64)\n\n        # Geochemistry branch: (5, 16, 16) → 32\n        self.geochem_conv = nn.Conv2d(5, 16, 3, padding=1)\n        self.geochem_fc = nn.Linear(16 * 16 * 16, 32)\n\n        # Fusion MLP: 224 → 128 → 64 → latent\n        self.fusion = nn.Sequential(\n            nn.Linear(224, 128), nn.ReLU(),\n            nn.Linear(128, 64), nn.ReLU(),\n        )\n        self.mu_head = nn.Linear(64, latent_dim)\n        self.logvar_head = nn.Linear(64, latent_dim)\n\n    def forward(self, mag_grid, grav_grid, hyper_img, geochem_grid):\n        # mag_grid: (20, 20) → (1, 1, 20, 20)\n        m = F.gelu(self.mag_conv1(mag_grid.unsqueeze(0).unsqueeze(0)))\n        m = F.gelu(self.mag_conv2(m))\n        m = F.gelu(self.mag_fc(m.flatten()))\n\n        g = F.gelu(self.grav_conv1(grav_grid.unsqueeze(0).unsqueeze(0)))\n        g = F.gelu(self.grav_conv2(g))\n        g = F.gelu(self.grav_fc(g.flatten()))\n\n        # hyper_img: (16, 16, 10) → (1, 10, 16, 16)\n        h = hyper_img.permute(2, 0, 1).unsqueeze(0)\n        h = F.gelu(self.hyper_conv1(h))\n        h = F.gelu(self.hyper_conv2(h))\n        h = F.gelu(self.hyper_fc(h.flatten()))\n\n        # geochem: (16, 16, 5) → (1, 5, 16, 16)\n        c = geochem_grid.permute(2, 0, 1).unsqueeze(0)\n        c = F.gelu(self.geochem_conv(c))\n        c = F.gelu(self.geochem_fc(c.flatten()))\n\n        fused = torch.cat([m, g, h, c])  # 64+64+64+32 = 224\n        fused = self.fusion(fused)\n        return self.mu_head(fused), self.logvar_head(fused)\n\n\nclass DecoderSusceptibility(nn.Module):\n    \"\"\"\n    (latent, coord_norm, φ_gempy, unit_embedding) → χ_local.\n    GemPy scalar field provides geological structure awareness.\n    MC Dropout for Bayesian uncertainty.\n    \"\"\"\n    def __init__(self, latent_dim=32, n_units=4, embed_dim=4, dropout=0.1):\n        super().__init__()\n        self.unit_embed = nn.Embedding(n_units, embed_dim)\n        input_dim = latent_dim + 3 + 1 + embed_dim  # z + coord + φ + unit_emb\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 128), nn.GELU(), nn.Dropout(dropout),\n            nn.Linear(128, 64), nn.GELU(), nn.Dropout(dropout),\n            nn.Linear(64, 32), nn.GELU(),\n            nn.Linear(32, 1),\n        )\n\n    def forward(self, latent, coord, phi, unit_id):\n        \"\"\"\n        latent: (latent_dim,) or (N, latent_dim)\n        coord: (3,) or (N, 3)\n        phi: scalar or (N,)\n        unit_id: int or (N,) long tensor\n        \"\"\"\n        u_emb = self.unit_embed(unit_id)\n        if phi.dim() == 0:\n            phi = phi.unsqueeze(0)\n        if phi.dim() == 1 and latent.dim() == 1:\n            x = torch.cat([latent, coord, phi, u_emb])\n        else:\n            x = torch.cat([latent, coord, phi.unsqueeze(-1) if phi.dim() == 1 else phi, u_emb], dim=-1)\n        return F.softplus(self.net(x).squeeze(-1)) * 0.01\n\n\nclass DecoderDensity(nn.Module):\n    \"\"\"(latent, coord_norm, φ_gempy, unit_embedding) → Δρ_local.\"\"\"\n    def __init__(self, latent_dim=32, n_units=4, embed_dim=4, dropout=0.1):\n        super().__init__()\n        self.unit_embed = nn.Embedding(n_units, embed_dim)\n        input_dim = latent_dim + 3 + 1 + embed_dim\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 128), nn.GELU(), nn.Dropout(dropout),\n            nn.Linear(128, 64), nn.GELU(), nn.Dropout(dropout),\n            nn.Linear(64, 32), nn.GELU(),\n            nn.Linear(32, 1),\n        )\n\n    def forward(self, latent, coord, phi, unit_id):\n        u_emb = self.unit_embed(unit_id)\n        if phi.dim() == 0:\n            phi = phi.unsqueeze(0)\n        if phi.dim() == 1 and latent.dim() == 1:\n            x = torch.cat([latent, coord, phi, u_emb])\n        else:\n            x = torch.cat([latent, coord, phi.unsqueeze(-1) if phi.dim() == 1 else phi, u_emb], dim=-1)\n        return F.softplus(self.net(x).squeeze(-1)) * 0.1\n\n\nclass DecoderILR(nn.Module):\n    \"\"\"\n    (latent, coord, φ, unit_id, χ, ρ) → ILR compositions (3-dim).\n    Receives physical properties as inputs — bridges geophysics to geochemistry.\n    \"\"\"\n    def __init__(self, latent_dim=32, n_units=4, embed_dim=4, dropout=0.1):\n        super().__init__()\n        self.unit_embed = nn.Embedding(n_units, embed_dim)\n        input_dim = latent_dim + 3 + 1 + embed_dim + 2  # + chi_scaled + rho_scaled\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 64), nn.ReLU(), nn.Dropout(dropout),\n            nn.Linear(64, 32), nn.ReLU(), nn.Dropout(dropout),\n            nn.Linear(32, 3),\n        )\n\n    def forward(self, latent, coord, phi, unit_id, chi_local, rho_local):\n        u_emb = self.unit_embed(unit_id)\n        if phi.dim() == 0:\n            phi = phi.unsqueeze(0)\n\n        # Scale physical properties to similar magnitude as other inputs\n        chi_s = (chi_local * 100).unsqueeze(-1) if chi_local.dim() == 1 else (chi_local * 100)\n        rho_s = (rho_local * 10).unsqueeze(-1) if rho_local.dim() == 1 else (rho_local * 10)\n\n        if latent.dim() == 1:\n            x = torch.cat([latent, coord, phi, u_emb, chi_s, rho_s])\n        else:\n            x = torch.cat([latent, coord,\n                           phi.unsqueeze(-1) if phi.dim() == 1 else phi,\n                           u_emb, chi_s, rho_s], dim=-1)\n        return self.net(x)"},{"block_group":"ce41ffb4dd6a4ad8b43638a65d7161cf","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"eeaa4ab4535547efad61922a87009183","deepnote_block_group":"ce41ffb4dd6a4ad8b43638a65d7161cf","deepnote_cell_type":"text-cell-h2","deepnote_sorting_key":"28","deepnote_source":"Multi-physics loss"},"source":"## Multi\\-physics loss"},{"block_group":"f1d5ffe6e6b744439a688e5f99b80297","cell_type":"code","execution_count":54,"metadata":{"execution_start":1770257100966,"execution_millis":0,"source_hash":"754caec5","execution_context_id":"a3ebaa0d-42ee-47b9-ad2b-cdae02ced48a","cell_id":"f0e6f21bbf2141b7949f7e8a06615271","deepnote_block_group":"f1d5ffe6e6b744439a688e5f99b80297","deepnote_cell_type":"code","deepnote_sorting_key":"29","deepnote_content_hash":"754caec5","deepnote_execution_started_at":"2026-02-05T02:05:00.966Z","deepnote_execution_finished_at":"2026-02-05T02:05:00.966Z","deepnote_source":"def loss_fn(encoder, dec_susc, dec_dens, dec_ilr,\n            mag_grid_t, grav_grid_t, hyper_t, geochem_t,\n            mag_obs_t, grav_obs_t,\n            all_coords_t, all_phi_t, all_unit_ids_t,\n            train_coords_t, train_phi_t, train_unit_ids_t,\n            train_ilr_t, train_ilr_std_t, train_cell_idx,\n            lambda_recon=10.0, lambda_mag=1.0, lambda_grav=0.3):\n    \"\"\"\n    Multi-physics loss with GemPy structural conditioning.\n    Dropout is active during training (model.train() mode).\n    \"\"\"\n    # --- Encode → deterministic latent ---\n    mu, log_var = encoder(mag_grid_t, grav_grid_t, hyper_t, geochem_t)\n    z = mu  # deterministic\n\n    # --- Decode at ALL cells (z broadcast to each cell) ---\n    z_expanded = z.unsqueeze(0).expand(all_coords_t.shape[0], -1)\n    chi_pred = dec_susc(z_expanded, all_coords_t, all_phi_t, all_unit_ids_t)\n    rho_pred = dec_dens(z_expanded, all_coords_t, all_phi_t, all_unit_ids_t)\n\n    # --- Forward physics ---\n    mag_pred = forward_magnetic(chi_pred)\n    grav_pred = forward_gravity(rho_pred)\n\n    loss_mag = torch.mean((mag_pred - mag_obs_t)**2) / torch.var(mag_obs_t)\n    loss_grav = torch.mean((grav_pred - grav_obs_t)**2) / torch.var(grav_obs_t)\n\n    # --- Decode ILR at drill holes ---\n    chi_at_train = chi_pred[train_cell_idx]\n    rho_at_train = rho_pred[train_cell_idx]\n\n    z_train = z.unsqueeze(0).expand(train_coords_t.shape[0], -1)\n    ilr_pred = dec_ilr(z_train, train_coords_t, train_phi_t,\n                       train_unit_ids_t, chi_at_train, rho_at_train)\n\n    loss_recon = torch.mean(((ilr_pred - train_ilr_t) / train_ilr_std_t)**2)\n\n    # --- Rho bounding penalty (sum-based) ---\n    loss_rho_bound = torch.sum(torch.clamp(rho_pred - 0.25, min=0.0)**2)\n\n    # --- Total ---\n    loss_total = (lambda_recon * loss_recon\n                  + lambda_mag * loss_mag\n                  + lambda_grav * loss_grav\n                  + 1.0 * loss_rho_bound)\n\n    return loss_total, {\n        'total': loss_total.item(), 'recon': loss_recon.item(),\n        'mag': loss_mag.item(), 'grav': loss_grav.item(),\n        'chi_max': chi_pred.max().item(), 'rho_max': rho_pred.max().item(),\n        'rho_bnd': loss_rho_bound.item()\n    }"},"outputs":[],"source":"def loss_fn(encoder, dec_susc, dec_dens, dec_ilr,\n            mag_grid_t, grav_grid_t, hyper_t, geochem_t,\n            mag_obs_t, grav_obs_t,\n            all_coords_t, all_phi_t, all_unit_ids_t,\n            train_coords_t, train_phi_t, train_unit_ids_t,\n            train_ilr_t, train_ilr_std_t, train_cell_idx,\n            lambda_recon=10.0, lambda_mag=1.0, lambda_grav=0.3):\n    \"\"\"\n    Multi-physics loss with GemPy structural conditioning.\n    Dropout is active during training (model.train() mode).\n    \"\"\"\n    # --- Encode → deterministic latent ---\n    mu, log_var = encoder(mag_grid_t, grav_grid_t, hyper_t, geochem_t)\n    z = mu  # deterministic\n\n    # --- Decode at ALL cells (z broadcast to each cell) ---\n    z_expanded = z.unsqueeze(0).expand(all_coords_t.shape[0], -1)\n    chi_pred = dec_susc(z_expanded, all_coords_t, all_phi_t, all_unit_ids_t)\n    rho_pred = dec_dens(z_expanded, all_coords_t, all_phi_t, all_unit_ids_t)\n\n    # --- Forward physics ---\n    mag_pred = forward_magnetic(chi_pred)\n    grav_pred = forward_gravity(rho_pred)\n\n    loss_mag = torch.mean((mag_pred - mag_obs_t)**2) / torch.var(mag_obs_t)\n    loss_grav = torch.mean((grav_pred - grav_obs_t)**2) / torch.var(grav_obs_t)\n\n    # --- Decode ILR at drill holes ---\n    chi_at_train = chi_pred[train_cell_idx]\n    rho_at_train = rho_pred[train_cell_idx]\n\n    z_train = z.unsqueeze(0).expand(train_coords_t.shape[0], -1)\n    ilr_pred = dec_ilr(z_train, train_coords_t, train_phi_t,\n                       train_unit_ids_t, chi_at_train, rho_at_train)\n\n    loss_recon = torch.mean(((ilr_pred - train_ilr_t) / train_ilr_std_t)**2)\n\n    # --- Rho bounding penalty (sum-based) ---\n    loss_rho_bound = torch.sum(torch.clamp(rho_pred - 0.25, min=0.0)**2)\n\n    # --- Total ---\n    loss_total = (lambda_recon * loss_recon\n                  + lambda_mag * loss_mag\n                  + lambda_grav * loss_grav\n                  + 1.0 * loss_rho_bound)\n\n    return loss_total, {\n        'total': loss_total.item(), 'recon': loss_recon.item(),\n        'mag': loss_mag.item(), 'grav': loss_grav.item(),\n        'chi_max': chi_pred.max().item(), 'rho_max': rho_pred.max().item(),\n        'rho_bnd': loss_rho_bound.item()\n    }"},{"block_group":"2e20e337493c4dcf8d260888f12ffb41","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"a4eeedf381254cc8a74df68599b7d6d2","deepnote_block_group":"2e20e337493c4dcf8d260888f12ffb41","deepnote_cell_type":"text-cell-h2","deepnote_sorting_key":"30","deepnote_source":"Model fitting"},"source":"## Model fitting"},{"block_group":"eb57f05d06564fa7996bb39413c05e17","cell_type":"code","execution_count":null,"metadata":{"execution_start":1770257110201,"execution_millis":19,"source_hash":"f34af0d4","execution_context_id":"a3ebaa0d-42ee-47b9-ad2b-cdae02ced48a","cell_id":"0c1d0fa1b7a5419eb18c54d70a1e20a1","deepnote_block_group":"eb57f05d06564fa7996bb39413c05e17","deepnote_cell_type":"code","deepnote_sorting_key":"31","deepnote_content_hash":"f34af0d4","deepnote_execution_started_at":"2026-02-05T02:05:10.201Z","deepnote_execution_finished_at":"2026-02-05T02:05:10.220Z","deepnote_source":"# Initialize models\nlatent_dim = 32\nencoder = MultiModalEncoder(latent_dim=latent_dim)\ndec_susc = DecoderSusceptibility(latent_dim=latent_dim, n_units=n_lith)\ndec_dens = DecoderDensity(latent_dim=latent_dim, n_units=n_lith)\ndec_ilr = DecoderILR(latent_dim=latent_dim, n_units=n_lith)\n\n# Count parameters\nn_params = sum(p.numel() for p in encoder.parameters())\nn_params += sum(p.numel() for m in [dec_susc, dec_dens, dec_ilr] for p in m.parameters())\nprint(f\"Total parameters: {n_params:,}\")\n\n# Prepare data tensors\nmag_grid_t = torch.tensor(mag_observed.reshape(n_stations_mag, n_stations_mag), dtype=torch.float32)\nmag_grid_t = (mag_grid_t - mag_grid_t.mean()) / (mag_grid_t.std() + 1e-6)\n\ngrav_grid_t = torch.tensor(grav_observed.reshape(n_stations_mag, n_stations_mag), dtype=torch.float32)\ngrav_grid_t = (grav_grid_t - grav_grid_t.mean()) / (grav_grid_t.std() + 1e-6)\n\nhyper_t = torch.tensor(hyper_image, dtype=torch.float32)\ngeochem_t = torch.tensor(geochem_grid_2d, dtype=torch.float32)\n\nmag_obs_t = torch.tensor(mag_observed, dtype=torch.float32)\ngrav_obs_t = torch.tensor(grav_observed, dtype=torch.float32)\n\n# Coordinates (normalized)\ncoord_mean = np.array([nx*dx/2, ny*dy/2, -nz*dz/2])\ncoord_std = np.array([nx*dx/2, ny*dy/2, nz*dz/2])\nall_coords_t = torch.tensor((cc - coord_mean) / coord_std, dtype=torch.float32)\nall_phi_t = torch.tensor(scalar_field_norm, dtype=torch.float32)\nall_unit_ids_t = torch.tensor(cell_lith_id, dtype=torch.long)\n\ntrain_coords_t = torch.tensor((df_train[['x', 'y', 'z']].values - coord_mean) / coord_std, dtype=torch.float32)\ntrain_ilr_t = torch.tensor(df_train[['ilr0', 'ilr1', 'ilr2']].values, dtype=torch.float32)\ntrain_ilr_std_t = train_ilr_t.std(dim=0)\ntrain_cell_idx = torch.tensor(df_train['cell_idx'].values, dtype=torch.long)\n\n# GemPy features for train drill holes\ntrain_phi_t = all_phi_t[train_cell_idx]\ntrain_unit_ids_t = all_unit_ids_t[train_cell_idx]\n\nval_coords_t = torch.tensor((df_val[['x', 'y', 'z']].values - coord_mean) / coord_std, dtype=torch.float32)\nval_ilr_t = torch.tensor(df_val[['ilr0', 'ilr1', 'ilr2']].values, dtype=torch.float32)\nval_cell_idx = torch.tensor(df_val['cell_idx'].values, dtype=torch.long)\n\nprint(\"Data prepared for training\")\n\n# Optimizer with cosine annealing\nn_epochs = 25000\nall_params = (list(encoder.parameters()) + list(dec_susc.parameters())\n              + list(dec_dens.parameters()) + list(dec_ilr.parameters()))\noptimizer = torch.optim.Adam(all_params, lr=2e-3)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=n_epochs, eta_min=1e-5)\n\n# Manual warmup for first 500 steps\nwarmup_steps = 500\n\n# Training loop\nhistory = []\n\nencoder.train()\ndec_susc.train()\ndec_dens.train()\ndec_ilr.train()\n\nfor epoch in range(n_epochs):\n    # Warmup: linearly increase LR from 1e-4 to 2e-3\n    if epoch < warmup_steps:\n        lr = 1e-4 + (2e-3 - 1e-4) * epoch / warmup_steps\n        for pg in optimizer.param_groups:\n            pg['lr'] = lr\n\n    optimizer.zero_grad()\n\n    loss, aux = loss_fn(\n        encoder, dec_susc, dec_dens, dec_ilr,\n        mag_grid_t, grav_grid_t, hyper_t, geochem_t,\n        mag_obs_t, grav_obs_t,\n        all_coords_t, all_phi_t, all_unit_ids_t,\n        train_coords_t, train_phi_t, train_unit_ids_t,\n        train_ilr_t, train_ilr_std_t, train_cell_idx,\n        lambda_recon=10.0, lambda_mag=1.0, lambda_grav=0.3\n    )\n\n    loss.backward()\n    torch.nn.utils.clip_grad_norm_(all_params, max_norm=1.0)\n    optimizer.step()\n\n    if epoch >= warmup_steps:\n        scheduler.step()\n\n    history.append({**aux, 'epoch': epoch})\n\n    if epoch % 2500 == 0:\n        print(f\"Epoch {epoch:5d} | loss={aux['total']:.4f} | recon={aux['recon']:.4f} | \"\n              f\"mag={aux['mag']:.4f} | grav={aux['grav']:.4f} | \"\n              f\"χ_max={aux['chi_max']:.5f} | ρ_max={aux['rho_max']:.5f}\")\n"},"outputs":[{"name":"stdout","text":"Total parameters: 2,387,845\nData prepared for training\nEpoch     0 | loss=2121.9385 | recon=187.0448 | mag=34.7842 | grav=722.3548 | χ_max=0.00599 | ρ_max=0.07135\nEpoch  2500 | loss=3.2107 | recon=0.3144 | mag=0.0374 | grav=0.0965 | χ_max=0.02720 | ρ_max=0.14029\nEpoch  5000 | loss=1.0452 | recon=0.0986 | mag=0.0346 | grav=0.0811 | χ_max=0.02786 | ρ_max=0.22963\nEpoch  7500 | loss=0.3636 | recon=0.0316 | mag=0.0251 | grav=0.0764 | χ_max=0.02752 | ρ_max=0.24464\nEpoch 10000 | loss=0.5085 | recon=0.0459 | mag=0.0266 | grav=0.0750 | χ_max=0.02698 | ρ_max=0.23336\nEpoch 12500 | loss=0.6451 | recon=0.0600 | mag=0.0232 | grav=0.0745 | χ_max=0.02706 | ρ_max=0.24026\nEpoch 15000 | loss=1.1005 | recon=0.1055 | mag=0.0237 | grav=0.0743 | χ_max=0.02597 | ρ_max=0.23974\nEpoch 17500 | loss=0.3166 | recon=0.0272 | mag=0.0228 | grav=0.0740 | χ_max=0.02657 | ρ_max=0.24815\nEpoch 20000 | loss=0.1846 | recon=0.0138 | mag=0.0244 | grav=0.0742 | χ_max=0.02679 | ρ_max=0.25521\nEpoch 22500 | loss=0.2650 | recon=0.0220 | mag=0.0229 | grav=0.0738 | χ_max=0.02675 | ρ_max=0.23893\n","output_type":"stream"}],"source":"# Initialize models\nlatent_dim = 32\nencoder = MultiModalEncoder(latent_dim=latent_dim)\ndec_susc = DecoderSusceptibility(latent_dim=latent_dim, n_units=n_lith)\ndec_dens = DecoderDensity(latent_dim=latent_dim, n_units=n_lith)\ndec_ilr = DecoderILR(latent_dim=latent_dim, n_units=n_lith)\n\n# Count parameters\nn_params = sum(p.numel() for p in encoder.parameters())\nn_params += sum(p.numel() for m in [dec_susc, dec_dens, dec_ilr] for p in m.parameters())\nprint(f\"Total parameters: {n_params:,}\")\n\n# Prepare data tensors\nmag_grid_t = torch.tensor(mag_observed.reshape(n_stations_mag, n_stations_mag), dtype=torch.float32)\nmag_grid_t = (mag_grid_t - mag_grid_t.mean()) / (mag_grid_t.std() + 1e-6)\n\ngrav_grid_t = torch.tensor(grav_observed.reshape(n_stations_mag, n_stations_mag), dtype=torch.float32)\ngrav_grid_t = (grav_grid_t - grav_grid_t.mean()) / (grav_grid_t.std() + 1e-6)\n\nhyper_t = torch.tensor(hyper_image, dtype=torch.float32)\ngeochem_t = torch.tensor(geochem_grid_2d, dtype=torch.float32)\n\nmag_obs_t = torch.tensor(mag_observed, dtype=torch.float32)\ngrav_obs_t = torch.tensor(grav_observed, dtype=torch.float32)\n\n# Coordinates (normalized)\ncoord_mean = np.array([nx*dx/2, ny*dy/2, -nz*dz/2])\ncoord_std = np.array([nx*dx/2, ny*dy/2, nz*dz/2])\nall_coords_t = torch.tensor((cc - coord_mean) / coord_std, dtype=torch.float32)\nall_phi_t = torch.tensor(scalar_field_norm, dtype=torch.float32)\nall_unit_ids_t = torch.tensor(cell_lith_id, dtype=torch.long)\n\ntrain_coords_t = torch.tensor((df_train[['x', 'y', 'z']].values - coord_mean) / coord_std, dtype=torch.float32)\ntrain_ilr_t = torch.tensor(df_train[['ilr0', 'ilr1', 'ilr2']].values, dtype=torch.float32)\ntrain_ilr_std_t = train_ilr_t.std(dim=0)\ntrain_cell_idx = torch.tensor(df_train['cell_idx'].values, dtype=torch.long)\n\n# GemPy features for train drill holes\ntrain_phi_t = all_phi_t[train_cell_idx]\ntrain_unit_ids_t = all_unit_ids_t[train_cell_idx]\n\nval_coords_t = torch.tensor((df_val[['x', 'y', 'z']].values - coord_mean) / coord_std, dtype=torch.float32)\nval_ilr_t = torch.tensor(df_val[['ilr0', 'ilr1', 'ilr2']].values, dtype=torch.float32)\nval_cell_idx = torch.tensor(df_val['cell_idx'].values, dtype=torch.long)\n\nprint(\"Data prepared for training\")\n\n# Optimizer with cosine annealing\nn_epochs = 25000\nall_params = (list(encoder.parameters()) + list(dec_susc.parameters())\n              + list(dec_dens.parameters()) + list(dec_ilr.parameters()))\noptimizer = torch.optim.Adam(all_params, lr=2e-3)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=n_epochs, eta_min=1e-5)\n\n# Manual warmup for first 500 steps\nwarmup_steps = 500\n\n# Training loop\nhistory = []\n\nencoder.train()\ndec_susc.train()\ndec_dens.train()\ndec_ilr.train()\n\nfor epoch in range(n_epochs):\n    # Warmup: linearly increase LR from 1e-4 to 2e-3\n    if epoch < warmup_steps:\n        lr = 1e-4 + (2e-3 - 1e-4) * epoch / warmup_steps\n        for pg in optimizer.param_groups:\n            pg['lr'] = lr\n\n    optimizer.zero_grad()\n\n    loss, aux = loss_fn(\n        encoder, dec_susc, dec_dens, dec_ilr,\n        mag_grid_t, grav_grid_t, hyper_t, geochem_t,\n        mag_obs_t, grav_obs_t,\n        all_coords_t, all_phi_t, all_unit_ids_t,\n        train_coords_t, train_phi_t, train_unit_ids_t,\n        train_ilr_t, train_ilr_std_t, train_cell_idx,\n        lambda_recon=10.0, lambda_mag=1.0, lambda_grav=0.3\n    )\n\n    loss.backward()\n    torch.nn.utils.clip_grad_norm_(all_params, max_norm=1.0)\n    optimizer.step()\n\n    if epoch >= warmup_steps:\n        scheduler.step()\n\n    history.append({**aux, 'epoch': epoch})\n\n    if epoch % 2500 == 0:\n        print(f\"Epoch {epoch:5d} | loss={aux['total']:.4f} | recon={aux['recon']:.4f} | \"\n              f\"mag={aux['mag']:.4f} | grav={aux['grav']:.4f} | \"\n              f\"χ_max={aux['chi_max']:.5f} | ρ_max={aux['rho_max']:.5f}\")\n"},{"block_group":"a75751080cac4e2cbae73871335cc977","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"2a9d6a6e3e004ad0867e9fff5b38e73a","deepnote_block_group":"a75751080cac4e2cbae73871335cc977","deepnote_cell_type":"text-cell-p","deepnote_sorting_key":"32","deepnote_source":"Training curves"},"source":"Training curves"},{"block_group":"8badcede49e14683b32b16ea3b392a62","cell_type":"code","execution_count":null,"metadata":{"deepnote_to_be_reexecuted":true,"cell_id":"03f1c0c4726244db837f065fc266e247","deepnote_block_group":"8badcede49e14683b32b16ea3b392a62","deepnote_cell_type":"code","deepnote_sorting_key":"33","deepnote_source":"df_hist = pd.DataFrame(history)\n(\n    lp.ggplot(df_hist, lp.aes(x='epoch'))\n    + lp.geom_line(lp.aes(y='recon'), color=\"#962561\")\n    + lp.geom_line(lp.aes(y='mag'), color=\"#abc000\")\n    + lp.geom_line(lp.aes(y='grav'), color=\"#006080\")\n    + lp.scale_y_log10()\n    + lp.labs(title='Training losses', x='Epoch', y='Loss (log)')\n)"},"outputs":[],"source":"df_hist = pd.DataFrame(history)\n(\n    lp.ggplot(df_hist, lp.aes(x='epoch'))\n    + lp.geom_line(lp.aes(y='recon'), color=\"#962561\")\n    + lp.geom_line(lp.aes(y='mag'), color=\"#abc000\")\n    + lp.geom_line(lp.aes(y='grav'), color=\"#006080\")\n    + lp.scale_y_log10()\n    + lp.labs(title='Training losses', x='Epoch', y='Loss (log)')\n)"},{"block_group":"dd73be8821ca46f5a684ead7a3a5980a","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"e2aafbd2a69b4e1f9d2accaa91b5777c","deepnote_block_group":"dd73be8821ca46f5a684ead7a3a5980a","deepnote_cell_type":"text-cell-h2","deepnote_sorting_key":"34","deepnote_source":"Predictions with MC Dropout Uncertainty"},"source":"## Predictions with MC Dropout Uncertainty"},{"block_group":"4619e75d1ea34409ac1197af64e4f9ba","cell_type":"code","execution_count":null,"metadata":{"cell_id":"bf6a87a77be14cf7ae1cedd532b87a17","deepnote_block_group":"4619e75d1ea34409ac1197af64e4f9ba","deepnote_cell_type":"code","deepnote_sorting_key":"35","deepnote_source":"# Deterministic predictions (dropout off)\nencoder.eval()\ndec_susc.eval()\ndec_dens.eval()\ndec_ilr.eval()\n\nwith torch.no_grad():\n    mu, log_var = encoder(mag_grid_t, grav_grid_t, hyper_t, geochem_t)\n    z_expanded = mu.unsqueeze(0).expand(all_coords_t.shape[0], -1)\n\n    chi_pred = dec_susc(z_expanded, all_coords_t, all_phi_t, all_unit_ids_t)\n    rho_pred = dec_dens(z_expanded, all_coords_t, all_phi_t, all_unit_ids_t)\n\nchi_pred_np = chi_pred.detach().numpy()\nrho_pred_np = rho_pred.detach().numpy()\n\nprint(f\"χ predicted: {chi_pred_np.min():.4f} – {chi_pred_np.max():.4f} SI\")\nprint(f\"χ true:      {susceptibility_true.min():.4f} – {susceptibility_true.max():.4f} SI\")\nprint(f\"Δρ predicted: {rho_pred_np.min():.3f} – {rho_pred_np.max():.3f} g/cc\")\nprint(f\"Δρ true:      {density_true.min():.3f} – {density_true.max():.3f} g/cc\")\n\n# MC Dropout uncertainty — keep dropout ON during inference\nn_mc_samples = 50\nchi_samples = []\nrho_samples = []\nilr_samples = []\n\n# Enable dropout for MC sampling\ndec_susc.train()\ndec_dens.train()\ndec_ilr.train()\n\nwith torch.no_grad():\n    mu, _ = encoder(mag_grid_t, grav_grid_t, hyper_t, geochem_t)\n    z_expanded = mu.unsqueeze(0).expand(all_coords_t.shape[0], -1)\n\n    for i in range(n_mc_samples):\n        chi_s = dec_susc(z_expanded, all_coords_t, all_phi_t, all_unit_ids_t)\n        rho_s = dec_dens(z_expanded, all_coords_t, all_phi_t, all_unit_ids_t)\n        ilr_s = dec_ilr(z_expanded, all_coords_t, all_phi_t, all_unit_ids_t, chi_s, rho_s)\n\n        chi_samples.append(chi_s.numpy())\n        rho_samples.append(rho_s.numpy())\n        ilr_samples.append(ilr_s.numpy())\n\nchi_samples = np.stack(chi_samples)\nrho_samples = np.stack(rho_samples)\nilr_samples = np.stack(ilr_samples)\n\nilr_mean = ilr_samples.mean(axis=0)\nilr_std = ilr_samples.std(axis=0)\nchi_mc_std = chi_samples.std(axis=0)\nrho_mc_std = rho_samples.std(axis=0)\n\nprint(f\"ILR predicted:   {ilr_mean.min():.2f} – {ilr_mean.max():.2f}\")\nprint(f\"ILR uncertainty: {ilr_std.min():.3f} – {ilr_std.max():.3f}\")\nprint(f\"χ uncertainty:   {chi_mc_std.min():.6f} – {chi_mc_std.max():.6f}\")\nprint(f\"Δρ uncertainty:  {rho_mc_std.min():.5f} – {rho_mc_std.max():.5f}\")\n\ncomp_pred = nuee.composition.ilr_inv(ilr_mean, basis=basis_ortho)\nCu_pred = comp_pred[:, 0]\n\nprint(f\"Cu predicted: {Cu_pred.min()*100:.2f}% – {Cu_pred.max()*100:.2f}%\")\nprint(f\"Cu true:      {Cu.min()*100:.2f}% – {Cu.max()*100:.2f}%\")\n\n# ## Validation Metrics\n\nencoder.eval()\ndec_susc.eval()\ndec_dens.eval()\ndec_ilr.eval()\n\ndef r2_score(true, pred):\n    ss_res = np.sum((true - pred)**2)\n    ss_tot = np.sum((true - true.mean())**2)\n    return 1 - ss_res / ss_tot\n\n# Physical property metrics\nchi_r2 = r2_score(susceptibility_true, chi_pred_np)\nrho_r2 = r2_score(density_true, rho_pred_np)\ncu_r2 = r2_score(Cu, Cu_pred)\ncu_corr = np.corrcoef(Cu, Cu_pred)[0, 1]\n\n# Validation ILR\nwith torch.no_grad():\n    mu, _ = encoder(mag_grid_t, grav_grid_t, hyper_t, geochem_t)\n    z_val = mu.unsqueeze(0).expand(val_coords_t.shape[0], -1)\n    chi_val = chi_pred[val_cell_idx]\n    rho_val = rho_pred[val_cell_idx]\n    val_phi_t = all_phi_t[val_cell_idx]\n    val_unit_ids_t = all_unit_ids_t[val_cell_idx]\n    val_ilr_pred = dec_ilr(z_val, val_coords_t, val_phi_t, val_unit_ids_t, chi_val, rho_val)\n\nval_rmse = float(torch.sqrt(torch.mean((val_ilr_pred - val_ilr_t)**2)))\n\nprint(f\"--- Validation Metrics ---\")\nprint(f\"χ global   R²: {chi_r2:.4f}\")\nprint(f\"Δρ global  R²: {rho_r2:.4f}\")\nprint(f\"Cu global  R²: {cu_r2:.4f} | corr: {cu_corr:.4f}\")\nprint(f\"ILR Val  RMSE: {val_rmse:.4f}\")"},"outputs":[],"source":"# Deterministic predictions (dropout off)\nencoder.eval()\ndec_susc.eval()\ndec_dens.eval()\ndec_ilr.eval()\n\nwith torch.no_grad():\n    mu, log_var = encoder(mag_grid_t, grav_grid_t, hyper_t, geochem_t)\n    z_expanded = mu.unsqueeze(0).expand(all_coords_t.shape[0], -1)\n\n    chi_pred = dec_susc(z_expanded, all_coords_t, all_phi_t, all_unit_ids_t)\n    rho_pred = dec_dens(z_expanded, all_coords_t, all_phi_t, all_unit_ids_t)\n\nchi_pred_np = chi_pred.detach().numpy()\nrho_pred_np = rho_pred.detach().numpy()\n\nprint(f\"χ predicted: {chi_pred_np.min():.4f} – {chi_pred_np.max():.4f} SI\")\nprint(f\"χ true:      {susceptibility_true.min():.4f} – {susceptibility_true.max():.4f} SI\")\nprint(f\"Δρ predicted: {rho_pred_np.min():.3f} – {rho_pred_np.max():.3f} g/cc\")\nprint(f\"Δρ true:      {density_true.min():.3f} – {density_true.max():.3f} g/cc\")\n\n# MC Dropout uncertainty — keep dropout ON during inference\nn_mc_samples = 50\nchi_samples = []\nrho_samples = []\nilr_samples = []\n\n# Enable dropout for MC sampling\ndec_susc.train()\ndec_dens.train()\ndec_ilr.train()\n\nwith torch.no_grad():\n    mu, _ = encoder(mag_grid_t, grav_grid_t, hyper_t, geochem_t)\n    z_expanded = mu.unsqueeze(0).expand(all_coords_t.shape[0], -1)\n\n    for i in range(n_mc_samples):\n        chi_s = dec_susc(z_expanded, all_coords_t, all_phi_t, all_unit_ids_t)\n        rho_s = dec_dens(z_expanded, all_coords_t, all_phi_t, all_unit_ids_t)\n        ilr_s = dec_ilr(z_expanded, all_coords_t, all_phi_t, all_unit_ids_t, chi_s, rho_s)\n\n        chi_samples.append(chi_s.numpy())\n        rho_samples.append(rho_s.numpy())\n        ilr_samples.append(ilr_s.numpy())\n\nchi_samples = np.stack(chi_samples)\nrho_samples = np.stack(rho_samples)\nilr_samples = np.stack(ilr_samples)\n\nilr_mean = ilr_samples.mean(axis=0)\nilr_std = ilr_samples.std(axis=0)\nchi_mc_std = chi_samples.std(axis=0)\nrho_mc_std = rho_samples.std(axis=0)\n\nprint(f\"ILR predicted:   {ilr_mean.min():.2f} – {ilr_mean.max():.2f}\")\nprint(f\"ILR uncertainty: {ilr_std.min():.3f} – {ilr_std.max():.3f}\")\nprint(f\"χ uncertainty:   {chi_mc_std.min():.6f} – {chi_mc_std.max():.6f}\")\nprint(f\"Δρ uncertainty:  {rho_mc_std.min():.5f} – {rho_mc_std.max():.5f}\")\n\ncomp_pred = nuee.composition.ilr_inv(ilr_mean, basis=basis_ortho)\nCu_pred = comp_pred[:, 0]\n\nprint(f\"Cu predicted: {Cu_pred.min()*100:.2f}% – {Cu_pred.max()*100:.2f}%\")\nprint(f\"Cu true:      {Cu.min()*100:.2f}% – {Cu.max()*100:.2f}%\")\n\n# ## Validation Metrics\n\nencoder.eval()\ndec_susc.eval()\ndec_dens.eval()\ndec_ilr.eval()\n\ndef r2_score(true, pred):\n    ss_res = np.sum((true - pred)**2)\n    ss_tot = np.sum((true - true.mean())**2)\n    return 1 - ss_res / ss_tot\n\n# Physical property metrics\nchi_r2 = r2_score(susceptibility_true, chi_pred_np)\nrho_r2 = r2_score(density_true, rho_pred_np)\ncu_r2 = r2_score(Cu, Cu_pred)\ncu_corr = np.corrcoef(Cu, Cu_pred)[0, 1]\n\n# Validation ILR\nwith torch.no_grad():\n    mu, _ = encoder(mag_grid_t, grav_grid_t, hyper_t, geochem_t)\n    z_val = mu.unsqueeze(0).expand(val_coords_t.shape[0], -1)\n    chi_val = chi_pred[val_cell_idx]\n    rho_val = rho_pred[val_cell_idx]\n    val_phi_t = all_phi_t[val_cell_idx]\n    val_unit_ids_t = all_unit_ids_t[val_cell_idx]\n    val_ilr_pred = dec_ilr(z_val, val_coords_t, val_phi_t, val_unit_ids_t, chi_val, rho_val)\n\nval_rmse = float(torch.sqrt(torch.mean((val_ilr_pred - val_ilr_t)**2)))\n\nprint(f\"--- Validation Metrics ---\")\nprint(f\"χ global   R²: {chi_r2:.4f}\")\nprint(f\"Δρ global  R²: {rho_r2:.4f}\")\nprint(f\"Cu global  R²: {cu_r2:.4f} | corr: {cu_corr:.4f}\")\nprint(f\"ILR Val  RMSE: {val_rmse:.4f}\")"},{"block_group":"c735c20aa22b4f0a8d007f7821c3e8be","cell_type":"markdown","execution_count":null,"metadata":{"formattedRanges":[],"cell_id":"93fa73627a134229bb2860a7cee6517b","deepnote_block_group":"c735c20aa22b4f0a8d007f7821c3e8be","deepnote_cell_type":"text-cell-h2","deepnote_sorting_key":"36","deepnote_source":"Visualizations"},"source":"## Visualizations"},{"block_group":"fea15dd18c6b437bbc519ff7e49fdd76","cell_type":"code","execution_count":null,"metadata":{"cell_id":"58859b85b92d46098ad251bcf8b16050","deepnote_block_group":"fea15dd18c6b437bbc519ff7e49fdd76","deepnote_cell_type":"code","deepnote_sorting_key":"37","deepnote_source":"iz = nz // 2\nidx_slice = slice(iz * nx * ny, (iz + 1) * nx * ny)\n\ndf_results = pd.DataFrame({\n    'x': cc[idx_slice, 0],\n    'y': cc[idx_slice, 1],\n    'chi_pred': chi_pred_np[idx_slice],\n    'chi_true': susceptibility_true[idx_slice],\n    'rho_pred': rho_pred_np[idx_slice],\n    'rho_true': density_true[idx_slice],\n    'Cu_pred': Cu_pred[idx_slice] * 100,\n    'Cu_true': Cu[idx_slice] * 100,\n    'uncertainty_ilr': ilr_std[idx_slice, 0],\n    'uncertainty_chi': chi_mc_std[idx_slice],\n    'uncertainty_rho': rho_mc_std[idx_slice],\n    'gempy_phi': scalar_field_norm[idx_slice],\n    'lithology': cell_lith_id[idx_slice],\n})\n\ndf_holes_train = df_train.drop_duplicates('hole')[['x', 'y']]\ndf_holes_val = df_val.drop_duplicates('hole')[['x', 'y']]"},"outputs":[],"source":"iz = nz // 2\nidx_slice = slice(iz * nx * ny, (iz + 1) * nx * ny)\n\ndf_results = pd.DataFrame({\n    'x': cc[idx_slice, 0],\n    'y': cc[idx_slice, 1],\n    'chi_pred': chi_pred_np[idx_slice],\n    'chi_true': susceptibility_true[idx_slice],\n    'rho_pred': rho_pred_np[idx_slice],\n    'rho_true': density_true[idx_slice],\n    'Cu_pred': Cu_pred[idx_slice] * 100,\n    'Cu_true': Cu[idx_slice] * 100,\n    'uncertainty_ilr': ilr_std[idx_slice, 0],\n    'uncertainty_chi': chi_mc_std[idx_slice],\n    'uncertainty_rho': rho_mc_std[idx_slice],\n    'gempy_phi': scalar_field_norm[idx_slice],\n    'lithology': cell_lith_id[idx_slice],\n})\n\ndf_holes_train = df_train.drop_duplicates('hole')[['x', 'y']]\ndf_holes_val = df_val.drop_duplicates('hole')[['x', 'y']]"},{"block_group":"16d79065c890484abe10a593507d1db2","cell_type":"code","execution_count":null,"metadata":{"cell_id":"641085adbe204dfcba8a4569e73a7e94","deepnote_block_group":"16d79065c890484abe10a593507d1db2","deepnote_cell_type":"code","deepnote_sorting_key":"38","deepnote_source":"(\n    lp.ggplot(df_results)\n    + lp.geom_tile(mapping=lp.aes('x', 'y', fill='gempy_phi'))\n    + lp.geom_point(data=df_holes_train, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black')\n    + lp.geom_point(data=df_holes_val, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black', fill=\"black\")\n    + lp.scale_fill_gradient2(low='blue', mid='white', high='red', midpoint=0.5)\n    + lp.labs(title=f'GemPy scalar field φ (z={mesh.cell_centers_z[iz]:.0f}m)', x='X', y='Y')\n)"},"outputs":[],"source":"(\n    lp.ggplot(df_results)\n    + lp.geom_tile(mapping=lp.aes('x', 'y', fill='gempy_phi'))\n    + lp.geom_point(data=df_holes_train, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black')\n    + lp.geom_point(data=df_holes_val, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black', fill=\"black\")\n    + lp.scale_fill_gradient2(low='blue', mid='white', high='red', midpoint=0.5)\n    + lp.labs(title=f'GemPy scalar field φ (z={mesh.cell_centers_z[iz]:.0f}m)', x='X', y='Y')\n)"},{"block_group":"6527bbb567804a22b3a94e8e26e93679","cell_type":"code","execution_count":null,"metadata":{"cell_id":"389eb814af1c4abb9cd9fb640353b53f","deepnote_block_group":"6527bbb567804a22b3a94e8e26e93679","deepnote_cell_type":"code","deepnote_sorting_key":"39","deepnote_source":"(\n    lp.ggplot(df_results)\n    + lp.geom_tile(mapping=lp.aes('x', 'y', fill='chi_pred'))\n    + lp.geom_point(data=df_holes_train, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black')\n    + lp.geom_point(data=df_holes_val, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black', fill=\"black\")\n    + lp.scale_fill_gradient(low='white', high='darkblue', name='χ (SI)')\n    + lp.labs(title=f'Predicted susceptibility (z={mesh.cell_centers_z[iz]:.0f}m)', x='X', y='Y')\n)"},"outputs":[],"source":"(\n    lp.ggplot(df_results)\n    + lp.geom_tile(mapping=lp.aes('x', 'y', fill='chi_pred'))\n    + lp.geom_point(data=df_holes_train, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black')\n    + lp.geom_point(data=df_holes_val, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black', fill=\"black\")\n    + lp.scale_fill_gradient(low='white', high='darkblue', name='χ (SI)')\n    + lp.labs(title=f'Predicted susceptibility (z={mesh.cell_centers_z[iz]:.0f}m)', x='X', y='Y')\n)"},{"block_group":"b5cc4cad6ae543d79f0ac00b45e4ef53","cell_type":"code","execution_count":null,"metadata":{"cell_id":"08e6e762b76f4390a079c80ef4fe8261","deepnote_block_group":"b5cc4cad6ae543d79f0ac00b45e4ef53","deepnote_cell_type":"code","deepnote_sorting_key":"40","deepnote_source":"(\n    lp.ggplot(df_results)\n    + lp.geom_tile(mapping=lp.aes('x', 'y', fill='chi_true'))\n    + lp.geom_point(data=df_holes_train, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black')\n    + lp.geom_point(data=df_holes_val, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black', fill=\"black\")\n    + lp.scale_fill_gradient(low='white', high='darkblue', name='χ (SI)')\n    + lp.labs(title=f'True susceptibility (z={mesh.cell_centers_z[iz]:.0f}m)', x='X', y='Y')\n)"},"outputs":[],"source":"(\n    lp.ggplot(df_results)\n    + lp.geom_tile(mapping=lp.aes('x', 'y', fill='chi_true'))\n    + lp.geom_point(data=df_holes_train, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black')\n    + lp.geom_point(data=df_holes_val, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black', fill=\"black\")\n    + lp.scale_fill_gradient(low='white', high='darkblue', name='χ (SI)')\n    + lp.labs(title=f'True susceptibility (z={mesh.cell_centers_z[iz]:.0f}m)', x='X', y='Y')\n)"},{"block_group":"2b881ecae9be4bee82f7c6e90a865061","cell_type":"code","execution_count":null,"metadata":{"cell_id":"77a07b8677e94d24a284facaa8cacc08","deepnote_block_group":"2b881ecae9be4bee82f7c6e90a865061","deepnote_cell_type":"code","deepnote_sorting_key":"41","deepnote_source":"(\n    lp.ggplot(df_results)\n    + lp.geom_tile(mapping=lp.aes('x', 'y', fill='rho_pred'))\n    + lp.geom_point(data=df_holes_train, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black')\n    + lp.geom_point(data=df_holes_val, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black', fill=\"black\")\n    + lp.scale_fill_gradient(low='white', high='#2d1b69', name='Δρ (g/cc)')\n    + lp.labs(title=f'Predicted density contrast (z={mesh.cell_centers_z[iz]:.0f}m)', x='X', y='Y')\n)"},"outputs":[],"source":"(\n    lp.ggplot(df_results)\n    + lp.geom_tile(mapping=lp.aes('x', 'y', fill='rho_pred'))\n    + lp.geom_point(data=df_holes_train, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black')\n    + lp.geom_point(data=df_holes_val, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black', fill=\"black\")\n    + lp.scale_fill_gradient(low='white', high='#2d1b69', name='Δρ (g/cc)')\n    + lp.labs(title=f'Predicted density contrast (z={mesh.cell_centers_z[iz]:.0f}m)', x='X', y='Y')\n)"},{"block_group":"ebd0e21d448b43308f25b0a040ba23d2","cell_type":"code","execution_count":null,"metadata":{"cell_id":"c3b6ab888e124b68bbe401d34cc6ae09","deepnote_block_group":"ebd0e21d448b43308f25b0a040ba23d2","deepnote_cell_type":"code","deepnote_sorting_key":"42","deepnote_source":"(\n    lp.ggplot(df_results)\n    + lp.geom_tile(mapping=lp.aes('x', 'y', fill='Cu_pred'))\n    + lp.geom_point(data=df_holes_train, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black')\n    + lp.geom_point(data=df_holes_val, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black', fill=\"black\")\n    + lp.scale_fill_gradient(low='white', high='darkred', name='Cu %')\n    + lp.labs(title=f'Predicted Cu (z={mesh.cell_centers_z[iz]:.0f}m)', x='X', y='Y')\n)"},"outputs":[],"source":"(\n    lp.ggplot(df_results)\n    + lp.geom_tile(mapping=lp.aes('x', 'y', fill='Cu_pred'))\n    + lp.geom_point(data=df_holes_train, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black')\n    + lp.geom_point(data=df_holes_val, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black', fill=\"black\")\n    + lp.scale_fill_gradient(low='white', high='darkred', name='Cu %')\n    + lp.labs(title=f'Predicted Cu (z={mesh.cell_centers_z[iz]:.0f}m)', x='X', y='Y')\n)"},{"block_group":"17a470e7bfde4477bb5a00dcc1f3843f","cell_type":"code","execution_count":null,"metadata":{"cell_id":"16ea9c5892684f4381afbfdc69477444","deepnote_block_group":"17a470e7bfde4477bb5a00dcc1f3843f","deepnote_cell_type":"code","deepnote_sorting_key":"43","deepnote_source":"(\n    lp.ggplot(df_results)\n    + lp.geom_tile(mapping=lp.aes('x', 'y', fill='Cu_true'))\n    + lp.geom_point(data=df_holes_train, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black')\n    + lp.geom_point(data=df_holes_val, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black', fill=\"black\")\n    + lp.scale_fill_gradient(low='white', high='darkred', name='Cu %')\n    + lp.labs(title=f'True Cu (z={mesh.cell_centers_z[iz]:.0f}m)', x='X', y='Y')\n)"},"outputs":[],"source":"(\n    lp.ggplot(df_results)\n    + lp.geom_tile(mapping=lp.aes('x', 'y', fill='Cu_true'))\n    + lp.geom_point(data=df_holes_train, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black')\n    + lp.geom_point(data=df_holes_val, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black', fill=\"black\")\n    + lp.scale_fill_gradient(low='white', high='darkred', name='Cu %')\n    + lp.labs(title=f'True Cu (z={mesh.cell_centers_z[iz]:.0f}m)', x='X', y='Y')\n)"},{"block_group":"5fbd6ca85b714bf18191b9e86d269aa2","cell_type":"code","execution_count":null,"metadata":{"cell_id":"477ec034fb464cecbd65e21185a5a14b","deepnote_block_group":"5fbd6ca85b714bf18191b9e86d269aa2","deepnote_cell_type":"code","deepnote_sorting_key":"44","deepnote_source":"(\n    lp.ggplot(df_results)\n    + lp.geom_tile(mapping=lp.aes('x', 'y', fill='uncertainty_chi'))\n    + lp.geom_point(data=df_holes_train, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black')\n    + lp.geom_point(data=df_holes_val, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black', fill=\"black\")\n    + lp.scale_fill_gradient(low='white', high='darkblue', name='σ_χ')\n    + lp.labs(title=f'MC Dropout uncertainty — susceptibility (z={mesh.cell_centers_z[iz]:.0f}m)', x='X', y='Y')\n)"},"outputs":[],"source":"(\n    lp.ggplot(df_results)\n    + lp.geom_tile(mapping=lp.aes('x', 'y', fill='uncertainty_chi'))\n    + lp.geom_point(data=df_holes_train, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black')\n    + lp.geom_point(data=df_holes_val, mapping=lp.aes('x', 'y'), shape=21, size=3, color='black', fill=\"black\")\n    + lp.scale_fill_gradient(low='white', high='darkblue', name='σ_χ')\n    + lp.labs(title=f'MC Dropout uncertainty — susceptibility (z={mesh.cell_centers_z[iz]:.0f}m)', x='X', y='Y')\n)"},{"block_group":"c8714f01010f42a4b89187a5c4d2a112","cell_type":"code","execution_count":null,"metadata":{"cell_id":"14d3a1367a1c421599a3f2afb5daf34e","deepnote_block_group":"c8714f01010f42a4b89187a5c4d2a112","deepnote_cell_type":"code","deepnote_sorting_key":"45","deepnote_source":"(\n    lp.ggplot(df_results, lp.aes('chi_true', 'chi_pred'))\n    + lp.geom_abline(slope=1, intercept=0, color='red')\n    + lp.geom_point(alpha=0.5)\n    + lp.labs(title='Susceptibility: predicted vs true', x='χ true', y='χ predicted')\n)"},"outputs":[],"source":"(\n    lp.ggplot(df_results, lp.aes('chi_true', 'chi_pred'))\n    + lp.geom_abline(slope=1, intercept=0, color='red')\n    + lp.geom_point(alpha=0.5)\n    + lp.labs(title='Susceptibility: predicted vs true', x='χ true', y='χ predicted')\n)"},{"block_group":"90b18343dc4943c590d606da3a0dd1b0","cell_type":"code","execution_count":null,"metadata":{"cell_id":"6c07b79d2dca4eccb8a07dd376ee6e06","deepnote_block_group":"90b18343dc4943c590d606da3a0dd1b0","deepnote_cell_type":"code","deepnote_sorting_key":"46","deepnote_source":"(\n    lp.ggplot(df_results, lp.aes('Cu_true', 'Cu_pred'))\n    + lp.geom_abline(slope=1, intercept=0, color='red')\n    + lp.geom_point(alpha=0.5)\n    + lp.labs(title='Cu: predicted vs true', x='Cu true (%)', y='Cu predicted (%)')\n)"},"outputs":[],"source":"(\n    lp.ggplot(df_results, lp.aes('Cu_true', 'Cu_pred'))\n    + lp.geom_abline(slope=1, intercept=0, color='red')\n    + lp.geom_point(alpha=0.5)\n    + lp.labs(title='Cu: predicted vs true', x='Cu true (%)', y='Cu predicted (%)')\n)"}],
        "metadata": {"deepnote_notebook_id":"fcf27e15ed304d22b6c11cffb34016c9"},
        "nbformat": "4",
        "nbformat_minor": "0",
        "version": "0"
      }